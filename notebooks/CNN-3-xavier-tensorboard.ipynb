{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn\n",
    "- <b>`scipy.io.wavfile`</b>\n",
    "- 0.5s chunk size, 0.25s window \n",
    "- mfcc\n",
    "- background data\n",
    "- sample rate 44100\n",
    "\n",
    "## Tensorboard 활용법\n",
    "- 커맨드 실행 (ex. notebooks 디렉토리에서 실행하면 notebooks/summaries 디렉토리 생성됨) `tensorboard --logdir=summaries`\n",
    "- http://localhost:6006\n",
    "- Session안에 Writer 정의\n",
    "- 트레이닝 루프에 merge 정의 `tf.summary.merge_all()`\n",
    "- Merge를 넣고 런해서 summary 얻음 `summary = sess.run([merge, cost, optimizer], feed_dict=feed_dict)`\n",
    "- Add summary `train_writer.add_summary(summary,epoch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "import scipy.io.wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load\n",
    "- uav: only p2 unloaded\n",
    "- none: some of the background sound and other sounds like gator/train\n",
    "    - `cnn_test_1532549868.wav`, `cnn_test_1532559744.wav`: KSQ 에어콘 소리 +말하는 소리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/phantom/JUNE_01_PHANTOMS/wavs/p2-unloaded/purdue_P2_unloaded_up_down.wav\n",
      "../data/phantom/JUNE_01_PHANTOMS/wavs/p2-unloaded/WSU_P2_DOWN_UNLOADED.wav\n",
      "../data/phantom/JUNE_01_PHANTOMS/wavs/p2-unloaded/WSU_P2_UNLOADED_BACK_AND_FORTH.wav\n",
      "../data/phantom/JUNE_01_PHANTOMS/wavs/p2-unloaded/WSU_P2_UNLOADED_UP_AND_DOWN.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/background_06_02_01.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/background_06_02_02.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/background_06_02_03.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/background_07_02_17.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/cnn_test_1532549868.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/cnn_test_1532559744.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/eric_survey.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/gator.wav\n",
      "../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/train_03.wav\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "uav_path = '../data/phantom/JUNE_01_PHANTOMS/wavs/p2-unloaded/*.wav'\n",
    "none_path = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/use/*.wav'\n",
    "uav_files = glob.glob(uav_path)\n",
    "none_files = glob.glob(none_path)\n",
    "print('\\n'.join(uav_files))\n",
    "print('\\n'.join(none_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 8192\n",
    "SR = 44100\n",
    "N_MFCC = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load2(files):\n",
    "    _, raw = scipy.io.wavfile.read(files[0])\n",
    "    for f in files[1:]:\n",
    "        _, array = scipy.io.wavfile.read(f)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3538944,)\n",
      "(8761977,)\n"
     ]
    }
   ],
   "source": [
    "uav_raw = load2(uav_files)\n",
    "none_raw = load2(none_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/Xy/uav_p2_unloaded_raw', uav_raw)\n",
    "np.save('../data/Xy/none_diverse_raw', none_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uav_raw = np.load('../data/Xy/uav_p2_unloaded_raw.npy')\n",
    "none_raw = np.load('../data/Xy/none_selected_raw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uav_raw = np.load('../data/Xy/uav_p2_unloaded_raw.npy')\n",
    "none_raw = np.load('../data/Xy/none_diverse_raw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uav_raw = uav_raw.astype(float)\n",
    "none_raw = none_raw.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "- features: mfcc, delta mfcc, delta2 mfcc, log spectrogram\n",
    "- 사용한피처: mfcc\n",
    "- 0.5초 청크, 0.25초 윈도우 슬라이드 (50% 오버랩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(X_uav, X_none, y_uav, y_none):\n",
    "    X = np.concatenate((X_uav, X_none), axis=0)\n",
    "    y = np.concatenate((y_uav, y_none), axis=0)\n",
    "    return X, y\n",
    "\n",
    "def onehot(y, n_classes):\n",
    "    y_encoded = np.zeros((y.shape[0], n_classes))\n",
    "    y_encoded[np.arange(y.shape[0]), y] = 1\n",
    "    print(y_encoded.shape)\n",
    "    return y_encoded\n",
    "\n",
    "def split_save(X, y, name, save=False):    \n",
    "        from sklearn import model_selection\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42)\n",
    "        if save:\n",
    "            np.save('../data/Xy/X_train_%s'%name, X_train)\n",
    "            np.save('../data/Xy/X_test_%s'%name, X_test)\n",
    "            np.save('../data/Xy/y_train_%s'%name, y_train)\n",
    "            np.save('../data/Xy/y_test_%s'%name, y_test)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_Xy(name):\n",
    "    X_train = np.load('../data/Xy/X_train_%s.npy'%name)\n",
    "    X_test = np.load('../data/Xy/X_test_%s.npy'%name)\n",
    "    y_train = np.load('../data/Xy/y_train_%s.npy'%name)\n",
    "    y_test = np.load('../data/Xy/y_test_%s.npy'%name)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk:한번에 처리하는 오디오 데이터 단위\n",
    "# window: 슬라이드하는 윈도우 크기\n",
    "# 50% overlap\n",
    "# chunk size 44100/2 --> n_frame 43 (n_frame은 mfcc.shape[1]인덱스사이즈)\n",
    "def mfcc5(raw, label, chunk_size=44100//2, window_size=44100//4, sr=44100, n_mfcc=16, n_frame=43):\n",
    "    mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    i = 0\n",
    "    while i+chunk_size <= len(raw):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc)\n",
    "        if mfcc_slice.shape[1] < n_frame+1:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0], mfcc_slice.shape[1]))\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "        i += window_size\n",
    "    y = np.array(y)\n",
    "    mfcc = mfcc.reshape(mfcc.shape[0], mfcc.shape[1], mfcc.shape[2], 1)\n",
    "    y = onehot(y, 2)\n",
    "    return mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_mfcc5\n",
    "# order 1 아니면 2 \n",
    "def delta_mfcc5(raw, label, order, chunk_size=44100//2, window_size=44100//4, sr=44100, n_mfcc=16, n_frame=43):\n",
    "    delta2_mfcc = np.empty((0, n_mfcc, n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    i = 0\n",
    "    while i+chunk_size <= len(raw):\n",
    "        S = librosa.feature.melspectrogram(raw[i:i+chunk_size], sr=sr, n_mels=128)\n",
    "        log_S = librosa.amplitude_to_db(S, ref=np.max)\n",
    "        mfcc_slice = librosa.feature.mfcc(S=log_S, sr=sr, n_mfcc=n_mfcc)\n",
    "        #print(delta_mfcc.shape)\n",
    "        delta2_mfcc_slice = librosa.feature.delta(mfcc_slice, order=order)\n",
    "        #print(delta2_mfcc_slice.shape)\n",
    "\n",
    "        #mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc)\n",
    "        if delta2_mfcc_slice.shape[1] < n_frame+1:\n",
    "            print(\"small end:\", delta2_mfcc_slice.shape)\n",
    "            continue\n",
    "        delta2_mfcc_slice = delta2_mfcc_slice[:,:-1]\n",
    "        delta2_mfcc_slice = delta2_mfcc_slice.reshape((1, delta2_mfcc_slice.shape[0], delta2_mfcc_slice.shape[1]))\n",
    "        #print(delta2_mfcc_slice.shape)\n",
    "        #print(delta2_mfcc.shape)\n",
    "        delta2_mfcc = np.vstack((delta2_mfcc, delta2_mfcc_slice))\n",
    "        y.append(label)\n",
    "        i += window_size\n",
    "    y = np.array(y)\n",
    "    delta2_mfcc = delta2_mfcc.reshape(delta2_mfcc.shape[0], delta2_mfcc.shape[1], delta2_mfcc.shape[2], 1)\n",
    "    y = onehot(y, 2)\n",
    "    return delta2_mfcc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_spectrogram 계산\n",
    "# n_frame사이즈 조정\n",
    "def log_spectrograms(raw, label, chunk_size=44100//2, window_size=44100//4, sr=44100, n_frame=49, n_freqs=442):\n",
    "    ls = np.empty((0, n_frame, n_freqs))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    i = 0\n",
    "\n",
    "    while i+chunk_size <= len(raw):\n",
    "        #(청크개수,freqs=442, time=47)\n",
    "        ls_slice = log_specgram(raw[i:i+chunk_size], sample_rate=sr)[2]\n",
    "        if ls_slice.shape[0] < n_frame:\n",
    "            print(\"small end:\", ls_slice.shape)\n",
    "            continue\n",
    "        ls_slice = ls_slice.reshape((1, ls_slice.shape[0], ls_slice.shape[1]))\n",
    "        #print(ls_slice.shape)\n",
    "        #print(ls.shape)\n",
    "        ls = np.vstack((ls, ls_slice))\n",
    "        y.append(label)\n",
    "        i += window_size\n",
    "    y = np.array(y)\n",
    "    ls = ls.reshape(ls.shape[0], ls.shape[1], ls.shape[2], 1)\n",
    "    y = onehot(y,2)\n",
    "    return ls, y\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "# log specgram one pass - 한번에...안썼음\n",
    "def log_specgram_one_pass(raw, label, sr=44100):\n",
    "    ls = log_specgram(raw, sample_rate=sr)[2]\n",
    "    ls = ls.reshape(ls.shape[0], ls.shape[1], 1)\n",
    "\n",
    "    y = [label]*ls.shape[0]\n",
    "    y = np.ones((ls.shape[0],),dtype=np.int)*label\n",
    "    print(y.shape)\n",
    "    y = onehot(y, 2)\n",
    "    return ls, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls_uav = log_spectrograms(uav_raw, 1)#freq 442...\n",
    "ls_none = log_spectrograms(none_raw, 0)#freq 442...\n",
    "print(ls_uav[0].shape, ls_uav[1].shape)\n",
    "print(ls_none[0].shape, ls_none[1].shape)\n",
    "\n",
    "X_ls, y_ls = combine(ls_uav[0], ls_none[0], ls_uav[1], ls_none[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_uav = log_specgram_one_pass(uav_raw, 1)#freq 442...\n",
    "ls_none = log_specgram_one_pass(none_raw, 0)#freq 442...\n",
    "print(ls_uav[0].shape, ls_uav[1].shape)\n",
    "print(ls_none[0].shape, ls_none[1].shape)\n",
    "\n",
    "X_ls, y_ls = combine(ls_uav[0], ls_none[0], ls_uav[1], ls_none[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta2_uav = delta_mfcc5(uav_raw, 1, order=2)\n",
    "print(delta2_uav[0].shape, delta2_uav[1].shape)\n",
    "delta2_none = delta_mfcc5(none_raw, 0, order=2)\n",
    "print(delta2_none[0].shape, delta2_none[1].shape)\n",
    "\n",
    "\n",
    "X_delta2, y_delta2 = combine(delta2_uav[0], delta2_none[0], delta2_uav[1], delta2_none[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta_uav = delta_mfcc5(uav_raw, 1, order=1)\n",
    "print(delta_uav[0].shape, delta_uav[1].shape)\n",
    "delta_none = delta_mfcc5(none_raw, 0, order=1)\n",
    "print(delta_none[0].shape, delta_none[1].shape)\n",
    "\n",
    "\n",
    "X_delta, y_delta = combine(delta_uav[0], delta_none[0], delta_uav[1], delta_none[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3538944,)\n",
      "(319, 2)\n",
      "(319, 16, 43, 1) (319, 2)\n",
      "(8761977,)\n",
      "(793, 2)\n",
      "(793, 16, 43, 1) (793, 2)\n"
     ]
    }
   ],
   "source": [
    "mfcc_uav = mfcc5(uav_raw, 1)\n",
    "print(mfcc_uav[0].shape, mfcc_uav[1].shape)\n",
    "mfcc_none = mfcc5(none_raw, 0)\n",
    "print(mfcc_none[0].shape, mfcc_none[1].shape)\n",
    "\n",
    "\n",
    "X_mfcc, y_mfcc = combine(mfcc_uav[0], mfcc_none[0], mfcc_uav[1], mfcc_none[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more background data (+ksquare ac sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_save(X_mfcc, y_mfcc, 'mfcc5_diverse_0726', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_Xy('mfcc5_diverse_0726')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gallagher's dataset selected background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_save(X_mfcc, y_mfcc, 'mfcc5_longwindow_0723', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_Xy('mfcc5_longwindow_0723')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_save(X_delta2, y_delta2, 'delta2', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_Xy('delta2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_save(X_delta, y_delta, 'delta', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_Xy('delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_save(X_ls, y_ls, 'logspec', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_Xy('logspec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 16, 43, 1) (176, 16, 43, 1)\n",
      "(703, 2) (176, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow finally!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- learning rate, epoch 유의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 16\n",
    "n_frame = 43\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Two convolutional layer\n",
    "- filter size: [13,4] n_mfcc가 16이고 frequency 대역이 중요해서 필터는 n_mfcc에 맞게 되도록 길게\n",
    "- <b>Xavier initializer</b> for both conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,n_mfcc*n_frame*n_channels])\n",
    "X = tf.reshape(X, [-1, n_mfcc, n_frame, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d/Relu:0\", shape=(?, 4, 40, 1), dtype=float32)\n",
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 4, 40, 1), dtype=float32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 4, 40, 1), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 2, 20, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# rectangular filter\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[13, 4],\n",
    "                         kernel_initializer=initializer,\n",
    "                         activation=tf.nn.relu)\n",
    "print(conv1)\n",
    "\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3],\n",
    "                                padding='SAME', strides=1)\n",
    "print(pool1)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[2, 2],\n",
    "                         kernel_initializer=initializer,\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "print(conv2)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=2)\n",
    "print(pool2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(?, 40), dtype=float32)\n",
      "Tensor(\"dense/Relu:0\", shape=(?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "flat = tf.reshape(pool2, [-1, 2*20*1])\n",
    "print(flat)\n",
    "\n",
    "dense3 = tf.layers.dense(inputs=flat, units=200, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense3, units=2)\n",
    "print(dense3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.placeholder(tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추적할 값들 저장하는 writer\n",
    "train_writer = tf.summary.FileWriter( './summaries/5/train ', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2d/kernel:0 is illegal; using conv2d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d/bias:0 is illegal; using conv2d/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0 is illegal; using conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0 is illegal; using conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n"
     ]
    }
   ],
   "source": [
    "# 모든 트레인가능한 변수 추적할거임\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var)\n",
    "    \n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost, accuracy도 추적할거임\n",
    "cost_ph = tf.placeholder(tf.float32,shape=None,name='cost_summary')\n",
    "cost_summary = tf.summary.scalar('cost', cost_ph)\n",
    "\n",
    "accuracy_ph = tf.placeholder(tf.float32,shape=None, name='accuracy_summary')\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy_ph)\n",
    "\n",
    "# 위에 두개 merge\n",
    "performance_summary = tf.summary.merge([cost_summary, accuracy_summary])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model save/restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/cnn/cnn_basic_xavier2_2'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/cnn/cnn_basic_xavier2_2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/cnn/cnn_basic_xavier2_2\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost =  0.047007716 validation: 0.8864\n",
      "Epoch: 0002 cost =  0.046119933 validation: 0.8864\n",
      "Epoch: 0003 cost =  0.032190574 validation: 0.8807\n",
      "Epoch: 0004 cost =  0.026117134 validation: 0.8807\n",
      "Epoch: 0005 cost =  0.025748257 validation: 0.8807\n",
      "Epoch: 0006 cost =  0.024927198 validation: 0.8807\n",
      "Epoch: 0007 cost =  0.023928186 validation: 0.8807\n",
      "Epoch: 0008 cost =  0.023551691 validation: 0.8807\n",
      "Epoch: 0009 cost =  0.023457921 validation: 0.8807\n",
      "Epoch: 0010 cost =  0.023246897 validation: 0.8750\n",
      "Epoch: 0011 cost =  0.023038668 validation: 0.8750\n",
      "Epoch: 0012 cost =  0.022928765 validation: 0.8750\n",
      "Epoch: 0013 cost =  0.022835743 validation: 0.8750\n",
      "Epoch: 0014 cost =  0.022726348 validation: 0.8750\n",
      "Epoch: 0015 cost =  0.022628257 validation: 0.8750\n",
      "Epoch: 0016 cost =  0.022578938 validation: 0.8750\n",
      "Epoch: 0017 cost =  0.022500012 validation: 0.8750\n",
      "Epoch: 0018 cost =  0.022426528 validation: 0.8750\n",
      "Epoch: 0019 cost =  0.022400617 validation: 0.8750\n",
      "Epoch: 0020 cost =  0.022321858 validation: 0.8750\n",
      "Epoch: 0021 cost =  0.022238834 validation: 0.8750\n",
      "Epoch: 0022 cost =  0.022212051 validation: 0.8750\n",
      "Epoch: 0023 cost =  0.022167590 validation: 0.8750\n",
      "Epoch: 0024 cost =  0.022125616 validation: 0.8750\n",
      "Epoch: 0025 cost =  0.022093278 validation: 0.8750\n",
      "Epoch: 0026 cost =  0.022048176 validation: 0.8750\n",
      "Epoch: 0027 cost =  0.022012620 validation: 0.8693\n",
      "Epoch: 0028 cost =  0.021964727 validation: 0.8693\n",
      "Epoch: 0029 cost =  0.021945158 validation: 0.8750\n",
      "Epoch: 0030 cost =  0.021931840 validation: 0.8750\n",
      "Epoch: 0031 cost =  0.021909463 validation: 0.8750\n",
      "Epoch: 0032 cost =  0.021860538 validation: 0.8750\n",
      "Epoch: 0033 cost =  0.021849856 validation: 0.8750\n",
      "Epoch: 0034 cost =  0.021809257 validation: 0.8750\n",
      "Epoch: 0035 cost =  0.021790945 validation: 0.8750\n",
      "Epoch: 0036 cost =  0.021773719 validation: 0.8750\n",
      "Epoch: 0037 cost =  0.021745039 validation: 0.8750\n",
      "Epoch: 0038 cost =  0.021713298 validation: 0.8750\n",
      "Epoch: 0039 cost =  0.021719256 validation: 0.8750\n",
      "Epoch: 0040 cost =  0.021697787 validation: 0.8750\n",
      "Epoch: 0041 cost =  0.021652731 validation: 0.8750\n",
      "Epoch: 0042 cost =  0.021654146 validation: 0.8750\n",
      "Epoch: 0043 cost =  0.021653632 validation: 0.8750\n",
      "Epoch: 0044 cost =  0.021611448 validation: 0.8750\n",
      "Epoch: 0045 cost =  0.021606609 validation: 0.8750\n",
      "Epoch: 0046 cost =  0.021596301 validation: 0.8693\n",
      "Epoch: 0047 cost =  0.021588422 validation: 0.8750\n",
      "Epoch: 0048 cost =  0.021582462 validation: 0.8750\n",
      "Epoch: 0049 cost =  0.021535558 validation: 0.8750\n",
      "Epoch: 0050 cost =  0.021551224 validation: 0.8750\n",
      "Epoch: 0051 cost =  0.021526864 validation: 0.8750\n",
      "Epoch: 0052 cost =  0.021497918 validation: 0.8750\n",
      "Epoch: 0053 cost =  0.021514612 validation: 0.8750\n",
      "Epoch: 0054 cost =  0.021524536 validation: 0.8750\n",
      "Epoch: 0055 cost =  0.021482981 validation: 0.8750\n",
      "Epoch: 0056 cost =  0.021480788 validation: 0.8750\n",
      "Epoch: 0057 cost =  0.021478222 validation: 0.8750\n",
      "Epoch: 0058 cost =  0.021464234 validation: 0.8750\n",
      "Epoch: 0059 cost =  0.021406843 validation: 0.8750\n",
      "Epoch: 0060 cost =  0.021434290 validation: 0.8750\n",
      "Epoch: 0061 cost =  0.021419395 validation: 0.8750\n",
      "Epoch: 0062 cost =  0.021409165 validation: 0.8750\n",
      "Epoch: 0063 cost =  0.021399271 validation: 0.8750\n",
      "Epoch: 0064 cost =  0.021386518 validation: 0.8750\n",
      "Epoch: 0065 cost =  0.021371830 validation: 0.8750\n",
      "Epoch: 0066 cost =  0.021377830 validation: 0.8750\n",
      "Epoch: 0067 cost =  0.021352697 validation: 0.8750\n",
      "Epoch: 0068 cost =  0.021353672 validation: 0.8750\n",
      "Epoch: 0069 cost =  0.021350949 validation: 0.8750\n",
      "Epoch: 0070 cost =  0.021332757 validation: 0.8750\n",
      "Epoch: 0071 cost =  0.021339079 validation: 0.8750\n",
      "Epoch: 0072 cost =  0.021320816 validation: 0.8750\n",
      "Epoch: 0073 cost =  0.021323179 validation: 0.8750\n",
      "Epoch: 0074 cost =  0.021319726 validation: 0.8750\n",
      "Epoch: 0075 cost =  0.021283342 validation: 0.8750\n",
      "Epoch: 0076 cost =  0.021293536 validation: 0.8750\n",
      "Epoch: 0077 cost =  0.021285660 validation: 0.8750\n",
      "Epoch: 0078 cost =  0.021268949 validation: 0.8750\n",
      "Epoch: 0079 cost =  0.021274949 validation: 0.8750\n",
      "Epoch: 0080 cost =  0.021278848 validation: 0.8750\n",
      "Epoch: 0081 cost =  0.021253530 validation: 0.8750\n",
      "Epoch: 0082 cost =  0.021243773 validation: 0.8750\n",
      "Epoch: 0083 cost =  0.021289633 validation: 0.8693\n",
      "Epoch: 0084 cost =  0.021259289 validation: 0.8750\n",
      "Epoch: 0085 cost =  0.021244983 validation: 0.8750\n",
      "Epoch: 0086 cost =  0.021249228 validation: 0.8750\n",
      "Epoch: 0087 cost =  0.021254327 validation: 0.8693\n",
      "Epoch: 0088 cost =  0.021228503 validation: 0.8693\n",
      "Epoch: 0089 cost =  0.021215925 validation: 0.8693\n",
      "Epoch: 0090 cost =  0.021190324 validation: 0.8693\n",
      "Epoch: 0091 cost =  0.021216225 validation: 0.8693\n",
      "Epoch: 0092 cost =  0.021205348 validation: 0.8693\n",
      "Epoch: 0093 cost =  0.021180868 validation: 0.8693\n",
      "Epoch: 0094 cost =  0.021197809 validation: 0.8693\n",
      "Epoch: 0095 cost =  0.021172484 validation: 0.8693\n",
      "Epoch: 0096 cost =  0.021166348 validation: 0.8693\n",
      "Epoch: 0097 cost =  0.021163269 validation: 0.8750\n",
      "Epoch: 0098 cost =  0.021166501 validation: 0.8750\n",
      "Epoch: 0099 cost =  0.021166517 validation: 0.8750\n",
      "Epoch: 0100 cost =  0.021141565 validation: 0.8750\n",
      "Epoch: 0101 cost =  0.021143583 validation: 0.8750\n",
      "Epoch: 0102 cost =  0.021126437 validation: 0.8750\n",
      "Epoch: 0103 cost =  0.021159702 validation: 0.8750\n",
      "Epoch: 0104 cost =  0.021166699 validation: 0.8750\n",
      "Epoch: 0105 cost =  0.021151743 validation: 0.8750\n",
      "Epoch: 0106 cost =  0.021147639 validation: 0.8750\n",
      "Epoch: 0107 cost =  0.021144517 validation: 0.8750\n",
      "Epoch: 0108 cost =  0.021134078 validation: 0.8750\n",
      "Epoch: 0109 cost =  0.021124871 validation: 0.8750\n",
      "Epoch: 0110 cost =  0.021128006 validation: 0.8750\n",
      "Epoch: 0111 cost =  0.021121999 validation: 0.8750\n",
      "Epoch: 0112 cost =  0.021083466 validation: 0.8750\n",
      "Epoch: 0113 cost =  0.021102146 validation: 0.8750\n",
      "Epoch: 0114 cost =  0.021088394 validation: 0.8750\n",
      "Epoch: 0115 cost =  0.021090682 validation: 0.8750\n",
      "Epoch: 0116 cost =  0.021078460 validation: 0.8750\n",
      "Epoch: 0117 cost =  0.021099032 validation: 0.8750\n",
      "Epoch: 0118 cost =  0.021086143 validation: 0.8750\n",
      "Epoch: 0119 cost =  0.021067034 validation: 0.8693\n",
      "Epoch: 0120 cost =  0.021082110 validation: 0.8693\n",
      "Epoch: 0121 cost =  0.021061723 validation: 0.8693\n",
      "Epoch: 0122 cost =  0.021065336 validation: 0.8693\n",
      "Epoch: 0123 cost =  0.021036445 validation: 0.8693\n",
      "Epoch: 0124 cost =  0.021130372 validation: 0.8693\n",
      "Epoch: 0125 cost =  0.021102575 validation: 0.8693\n",
      "Epoch: 0126 cost =  0.021063587 validation: 0.8636\n",
      "Epoch: 0127 cost =  0.021087266 validation: 0.8636\n",
      "Epoch: 0128 cost =  0.021115637 validation: 0.8580\n",
      "Epoch: 0129 cost =  0.021096365 validation: 0.8580\n",
      "Epoch: 0130 cost =  0.021094413 validation: 0.8636\n",
      "Epoch: 0131 cost =  0.021092271 validation: 0.8636\n",
      "Epoch: 0132 cost =  0.021066058 validation: 0.8580\n",
      "Epoch: 0133 cost =  0.021107693 validation: 0.8523\n",
      "Epoch: 0134 cost =  0.021052587 validation: 0.8523\n",
      "Epoch: 0135 cost =  0.021069526 validation: 0.8523\n",
      "Epoch: 0136 cost =  0.021076605 validation: 0.8580\n",
      "Epoch: 0137 cost =  0.021053658 validation: 0.8580\n",
      "Epoch: 0138 cost =  0.021061993 validation: 0.8580\n",
      "Epoch: 0139 cost =  0.021066299 validation: 0.8580\n",
      "Epoch: 0140 cost =  0.021037357 validation: 0.8580\n",
      "Epoch: 0141 cost =  0.021017744 validation: 0.8523\n",
      "Epoch: 0142 cost =  0.021031704 validation: 0.8523\n",
      "Epoch: 0143 cost =  0.021021853 validation: 0.8580\n",
      "Epoch: 0144 cost =  0.021007373 validation: 0.8523\n",
      "Epoch: 0145 cost =  0.021012249 validation: 0.8523\n",
      "Epoch: 0146 cost =  0.021006670 validation: 0.8523\n",
      "Epoch: 0147 cost =  0.021002830 validation: 0.8580\n",
      "Epoch: 0148 cost =  0.021039066 validation: 0.8523\n",
      "Epoch: 0149 cost =  0.021020768 validation: 0.8523\n",
      "Epoch: 0150 cost =  0.021005212 validation: 0.8523\n",
      "Epoch: 0151 cost =  0.021052819 validation: 0.8523\n",
      "Epoch: 0152 cost =  0.021031640 validation: 0.8580\n",
      "Epoch: 0153 cost =  0.021009391 validation: 0.8523\n",
      "Epoch: 0154 cost =  0.021024126 validation: 0.8523\n",
      "Epoch: 0155 cost =  0.021005048 validation: 0.8523\n",
      "Epoch: 0156 cost =  0.020999242 validation: 0.8580\n",
      "Epoch: 0157 cost =  0.020986845 validation: 0.8580\n",
      "Epoch: 0158 cost =  0.021004277 validation: 0.8580\n",
      "Epoch: 0159 cost =  0.021005456 validation: 0.8580\n",
      "Epoch: 0160 cost =  0.020981671 validation: 0.8523\n",
      "Epoch: 0161 cost =  0.021028291 validation: 0.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0162 cost =  0.021024115 validation: 0.8580\n",
      "Epoch: 0163 cost =  0.020993811 validation: 0.8580\n",
      "Epoch: 0164 cost =  0.021051446 validation: 0.8523\n",
      "Epoch: 0165 cost =  0.021010228 validation: 0.8523\n",
      "Epoch: 0166 cost =  0.021037781 validation: 0.8523\n",
      "Epoch: 0167 cost =  0.021014770 validation: 0.8523\n",
      "Epoch: 0168 cost =  0.020999990 validation: 0.8523\n",
      "Epoch: 0169 cost =  0.021023346 validation: 0.8523\n",
      "Epoch: 0170 cost =  0.021000689 validation: 0.8523\n",
      "Epoch: 0171 cost =  0.021007468 validation: 0.8523\n",
      "Epoch: 0172 cost =  0.020999211 validation: 0.8523\n",
      "Epoch: 0173 cost =  0.021000488 validation: 0.8523\n",
      "Epoch: 0174 cost =  0.020982775 validation: 0.8523\n",
      "Epoch: 0175 cost =  0.020993829 validation: 0.8523\n",
      "Epoch: 0176 cost =  0.020982423 validation: 0.8523\n",
      "Epoch: 0177 cost =  0.020983398 validation: 0.8523\n",
      "Epoch: 0178 cost =  0.020985730 validation: 0.8523\n",
      "Epoch: 0179 cost =  0.020974687 validation: 0.8523\n",
      "Epoch: 0180 cost =  0.020984138 validation: 0.8523\n",
      "Epoch: 0181 cost =  0.020955173 validation: 0.8523\n",
      "Epoch: 0182 cost =  0.020966711 validation: 0.8523\n",
      "Epoch: 0183 cost =  0.020957796 validation: 0.8523\n",
      "Epoch: 0184 cost =  0.020976767 validation: 0.8523\n",
      "Epoch: 0185 cost =  0.020966208 validation: 0.8523\n",
      "Epoch: 0186 cost =  0.020952301 validation: 0.8523\n",
      "Epoch: 0187 cost =  0.020991405 validation: 0.8523\n",
      "Epoch: 0188 cost =  0.020977595 validation: 0.8523\n",
      "Epoch: 0189 cost =  0.020971628 validation: 0.8523\n",
      "Epoch: 0190 cost =  0.020983623 validation: 0.8523\n",
      "Epoch: 0191 cost =  0.020964712 validation: 0.8523\n",
      "Epoch: 0192 cost =  0.020971516 validation: 0.8523\n",
      "Epoch: 0193 cost =  0.020970966 validation: 0.8523\n",
      "Epoch: 0194 cost =  0.020964366 validation: 0.8523\n",
      "Epoch: 0195 cost =  0.020964127 validation: 0.8523\n",
      "Epoch: 0196 cost =  0.020940143 validation: 0.8523\n",
      "Epoch: 0197 cost =  0.020994394 validation: 0.8523\n",
      "Epoch: 0198 cost =  0.021016424 validation: 0.8523\n",
      "Epoch: 0199 cost =  0.020962822 validation: 0.8523\n",
      "Epoch: 0200 cost =  0.021017993 validation: 0.8523\n",
      "Epoch: 0201 cost =  0.020997903 validation: 0.8523\n",
      "Epoch: 0202 cost =  0.020957854 validation: 0.8523\n",
      "Epoch: 0203 cost =  0.021003869 validation: 0.8523\n",
      "Epoch: 0204 cost =  0.020971584 validation: 0.8523\n",
      "Epoch: 0205 cost =  0.020933238 validation: 0.8523\n",
      "Epoch: 0206 cost =  0.020965689 validation: 0.8523\n",
      "Epoch: 0207 cost =  0.020934406 validation: 0.8523\n",
      "Epoch: 0208 cost =  0.020972075 validation: 0.8523\n",
      "Epoch: 0209 cost =  0.020959806 validation: 0.8523\n",
      "Epoch: 0210 cost =  0.020968577 validation: 0.8523\n",
      "Epoch: 0211 cost =  0.020967227 validation: 0.8523\n",
      "Epoch: 0212 cost =  0.020956871 validation: 0.8523\n",
      "Epoch: 0213 cost =  0.020949707 validation: 0.8523\n",
      "Epoch: 0214 cost =  0.020945196 validation: 0.8466\n",
      "Epoch: 0215 cost =  0.020952014 validation: 0.8523\n",
      "Epoch: 0216 cost =  0.020938395 validation: 0.8523\n",
      "Epoch: 0217 cost =  0.020974959 validation: 0.8466\n",
      "Epoch: 0218 cost =  0.020956768 validation: 0.8466\n",
      "Epoch: 0219 cost =  0.020959682 validation: 0.8466\n",
      "Epoch: 0220 cost =  0.020958548 validation: 0.8466\n",
      "Epoch: 0221 cost =  0.020958173 validation: 0.8466\n",
      "Epoch: 0222 cost =  0.020954134 validation: 0.8466\n",
      "Epoch: 0223 cost =  0.020951347 validation: 0.8466\n",
      "Epoch: 0224 cost =  0.020950712 validation: 0.8466\n",
      "Epoch: 0225 cost =  0.020942983 validation: 0.8466\n",
      "Epoch: 0226 cost =  0.020955573 validation: 0.8466\n",
      "Epoch: 0227 cost =  0.020938251 validation: 0.8466\n",
      "Epoch: 0228 cost =  0.020951706 validation: 0.8466\n",
      "Epoch: 0229 cost =  0.020944347 validation: 0.8466\n",
      "Epoch: 0230 cost =  0.020927038 validation: 0.8466\n",
      "Epoch: 0231 cost =  0.020936961 validation: 0.8466\n",
      "Epoch: 0232 cost =  0.020928110 validation: 0.8466\n",
      "Epoch: 0233 cost =  0.020932630 validation: 0.8466\n",
      "Epoch: 0234 cost =  0.020924282 validation: 0.8466\n",
      "Epoch: 0235 cost =  0.020918557 validation: 0.8466\n",
      "Epoch: 0236 cost =  0.020947781 validation: 0.8466\n",
      "Epoch: 0237 cost =  0.020923677 validation: 0.8466\n",
      "Epoch: 0238 cost =  0.020912522 validation: 0.8466\n",
      "Epoch: 0239 cost =  0.020941811 validation: 0.8466\n",
      "Epoch: 0240 cost =  0.020929923 validation: 0.8466\n",
      "Epoch: 0241 cost =  0.020973987 validation: 0.8466\n",
      "Epoch: 0242 cost =  0.020947216 validation: 0.8466\n",
      "Epoch: 0243 cost =  0.020934922 validation: 0.8466\n",
      "Epoch: 0244 cost =  0.020944295 validation: 0.8466\n",
      "Epoch: 0245 cost =  0.020933053 validation: 0.8466\n",
      "Epoch: 0246 cost =  0.020938842 validation: 0.8466\n",
      "Epoch: 0247 cost =  0.020940155 validation: 0.8466\n",
      "Epoch: 0248 cost =  0.020929178 validation: 0.8466\n",
      "Epoch: 0249 cost =  0.020939570 validation: 0.8466\n",
      "Epoch: 0250 cost =  0.020892155 validation: 0.8466\n",
      "Epoch: 0251 cost =  0.020917104 validation: 0.8466\n",
      "Epoch: 0252 cost =  0.020912841 validation: 0.8466\n",
      "Epoch: 0253 cost =  0.020891826 validation: 0.8466\n",
      "Epoch: 0254 cost =  0.020897300 validation: 0.8466\n",
      "Epoch: 0255 cost =  0.020892060 validation: 0.8466\n",
      "Epoch: 0256 cost =  0.020892887 validation: 0.8466\n",
      "Epoch: 0257 cost =  0.020887012 validation: 0.8466\n",
      "Epoch: 0258 cost =  0.020886842 validation: 0.8466\n",
      "Epoch: 0259 cost =  0.020916877 validation: 0.8466\n",
      "Epoch: 0260 cost =  0.020896859 validation: 0.8466\n",
      "Epoch: 0261 cost =  0.020891331 validation: 0.8466\n",
      "Epoch: 0262 cost =  0.020900882 validation: 0.8466\n",
      "Epoch: 0263 cost =  0.020896022 validation: 0.8466\n",
      "Epoch: 0264 cost =  0.020917423 validation: 0.8466\n",
      "Epoch: 0265 cost =  0.020931788 validation: 0.8466\n",
      "Epoch: 0266 cost =  0.020896714 validation: 0.8466\n",
      "Epoch: 0267 cost =  0.020905968 validation: 0.8466\n",
      "Epoch: 0268 cost =  0.020897677 validation: 0.8466\n",
      "Epoch: 0269 cost =  0.020895126 validation: 0.8523\n",
      "Epoch: 0270 cost =  0.020920818 validation: 0.8466\n",
      "Epoch: 0271 cost =  0.020901723 validation: 0.8466\n",
      "Epoch: 0272 cost =  0.020912347 validation: 0.8466\n",
      "Epoch: 0273 cost =  0.020875168 validation: 0.8466\n",
      "Epoch: 0274 cost =  0.020897139 validation: 0.8466\n",
      "Epoch: 0275 cost =  0.020887620 validation: 0.8466\n",
      "Epoch: 0276 cost =  0.020884819 validation: 0.8466\n",
      "Epoch: 0277 cost =  0.020902805 validation: 0.8466\n",
      "Epoch: 0278 cost =  0.020879931 validation: 0.8523\n",
      "Epoch: 0279 cost =  0.020896133 validation: 0.8466\n",
      "Epoch: 0280 cost =  0.020884676 validation: 0.8466\n",
      "Epoch: 0281 cost =  0.020875566 validation: 0.8466\n",
      "Epoch: 0282 cost =  0.020870462 validation: 0.8523\n",
      "Epoch: 0283 cost =  0.020880533 validation: 0.8523\n",
      "Epoch: 0284 cost =  0.020874571 validation: 0.8466\n",
      "Epoch: 0285 cost =  0.020873778 validation: 0.8466\n",
      "Epoch: 0286 cost =  0.020868630 validation: 0.8523\n",
      "Epoch: 0287 cost =  0.020868457 validation: 0.8523\n",
      "Epoch: 0288 cost =  0.020863585 validation: 0.8466\n",
      "Epoch: 0289 cost =  0.020902533 validation: 0.8466\n",
      "Epoch: 0290 cost =  0.020868234 validation: 0.8523\n",
      "Epoch: 0291 cost =  0.020893900 validation: 0.8523\n",
      "Epoch: 0292 cost =  0.020873491 validation: 0.8466\n",
      "Epoch: 0293 cost =  0.020865290 validation: 0.8523\n",
      "Epoch: 0294 cost =  0.020862367 validation: 0.8523\n",
      "Epoch: 0295 cost =  0.020855632 validation: 0.8523\n",
      "Epoch: 0296 cost =  0.020849822 validation: 0.8523\n",
      "Epoch: 0297 cost =  0.020932170 validation: 0.8523\n",
      "Epoch: 0298 cost =  0.020892606 validation: 0.8523\n",
      "Epoch: 0299 cost =  0.020890088 validation: 0.8466\n",
      "Epoch: 0300 cost =  0.020907597 validation: 0.8523\n",
      "Epoch: 0301 cost =  0.020910487 validation: 0.8523\n",
      "Epoch: 0302 cost =  0.020906899 validation: 0.8523\n",
      "Epoch: 0303 cost =  0.020898204 validation: 0.8523\n",
      "Epoch: 0304 cost =  0.020904905 validation: 0.8523\n",
      "Epoch: 0305 cost =  0.020891509 validation: 0.8466\n",
      "Epoch: 0306 cost =  0.020927784 validation: 0.8523\n",
      "Epoch: 0307 cost =  0.020877016 validation: 0.8523\n",
      "Epoch: 0308 cost =  0.020899734 validation: 0.8523\n",
      "Epoch: 0309 cost =  0.020888139 validation: 0.8523\n",
      "Epoch: 0310 cost =  0.020877669 validation: 0.8523\n",
      "Epoch: 0311 cost =  0.020942691 validation: 0.8523\n",
      "Epoch: 0312 cost =  0.020912532 validation: 0.8466\n",
      "Epoch: 0313 cost =  0.020924860 validation: 0.8523\n",
      "Epoch: 0314 cost =  0.020919331 validation: 0.8523\n",
      "Epoch: 0315 cost =  0.020905576 validation: 0.8523\n",
      "Epoch: 0316 cost =  0.020923266 validation: 0.8523\n",
      "Epoch: 0317 cost =  0.020892811 validation: 0.8580\n",
      "Epoch: 0318 cost =  0.020918578 validation: 0.8523\n",
      "Epoch: 0319 cost =  0.020877391 validation: 0.8523\n",
      "Epoch: 0320 cost =  0.020888168 validation: 0.8523\n",
      "Epoch: 0321 cost =  0.020867591 validation: 0.8580\n",
      "Epoch: 0322 cost =  0.020881693 validation: 0.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0323 cost =  0.020855629 validation: 0.8523\n",
      "Epoch: 0324 cost =  0.020875940 validation: 0.8523\n",
      "Epoch: 0325 cost =  0.020846363 validation: 0.8580\n",
      "Epoch: 0326 cost =  0.020868483 validation: 0.8523\n",
      "Epoch: 0327 cost =  0.020900600 validation: 0.8523\n",
      "Epoch: 0328 cost =  0.020887380 validation: 0.8523\n",
      "Epoch: 0329 cost =  0.020875197 validation: 0.8580\n",
      "Epoch: 0330 cost =  0.020886749 validation: 0.8523\n",
      "Epoch: 0331 cost =  0.020852446 validation: 0.8523\n",
      "Epoch: 0332 cost =  0.020858761 validation: 0.8523\n",
      "Epoch: 0333 cost =  0.020850208 validation: 0.8636\n",
      "Epoch: 0334 cost =  0.020861770 validation: 0.8523\n",
      "Epoch: 0335 cost =  0.020892852 validation: 0.8523\n",
      "Epoch: 0336 cost =  0.020880523 validation: 0.8523\n",
      "Epoch: 0337 cost =  0.020872776 validation: 0.8636\n",
      "Epoch: 0338 cost =  0.020875875 validation: 0.8523\n",
      "Epoch: 0339 cost =  0.020838371 validation: 0.8523\n",
      "Epoch: 0340 cost =  0.020862238 validation: 0.8523\n",
      "Epoch: 0341 cost =  0.020836631 validation: 0.8636\n",
      "Epoch: 0342 cost =  0.020846940 validation: 0.8580\n",
      "Epoch: 0343 cost =  0.020847650 validation: 0.8523\n",
      "Epoch: 0344 cost =  0.020846699 validation: 0.8580\n",
      "Epoch: 0345 cost =  0.020843931 validation: 0.8636\n",
      "Epoch: 0346 cost =  0.020838838 validation: 0.8636\n",
      "Epoch: 0347 cost =  0.020846825 validation: 0.8523\n",
      "Epoch: 0348 cost =  0.020838096 validation: 0.8580\n",
      "Epoch: 0349 cost =  0.020841279 validation: 0.8636\n",
      "Epoch: 0350 cost =  0.020814564 validation: 0.8636\n",
      "Epoch: 0351 cost =  0.020829180 validation: 0.8523\n",
      "Epoch: 0352 cost =  0.020825466 validation: 0.8580\n",
      "Epoch: 0353 cost =  0.020823588 validation: 0.8636\n",
      "Epoch: 0354 cost =  0.020814933 validation: 0.8636\n",
      "Epoch: 0355 cost =  0.020825721 validation: 0.8523\n",
      "Epoch: 0356 cost =  0.020813578 validation: 0.8636\n",
      "Epoch: 0357 cost =  0.020821755 validation: 0.8636\n",
      "Epoch: 0358 cost =  0.020812350 validation: 0.8636\n",
      "Epoch: 0359 cost =  0.020823905 validation: 0.8523\n",
      "Epoch: 0360 cost =  0.020823808 validation: 0.8636\n",
      "Epoch: 0361 cost =  0.020803447 validation: 0.8636\n",
      "Epoch: 0362 cost =  0.020866568 validation: 0.8636\n",
      "Epoch: 0363 cost =  0.020853929 validation: 0.8523\n",
      "Epoch: 0364 cost =  0.020823028 validation: 0.8636\n",
      "Epoch: 0365 cost =  0.020850523 validation: 0.8636\n",
      "Epoch: 0366 cost =  0.020822628 validation: 0.8636\n",
      "Epoch: 0367 cost =  0.020848009 validation: 0.8580\n",
      "Epoch: 0368 cost =  0.020829384 validation: 0.8636\n",
      "Epoch: 0369 cost =  0.020833511 validation: 0.8636\n",
      "Epoch: 0370 cost =  0.020829948 validation: 0.8693\n",
      "Epoch: 0371 cost =  0.020832909 validation: 0.8636\n",
      "Epoch: 0372 cost =  0.020835453 validation: 0.8693\n",
      "Epoch: 0373 cost =  0.020820357 validation: 0.8693\n",
      "Epoch: 0374 cost =  0.020828725 validation: 0.8693\n",
      "Epoch: 0375 cost =  0.020824531 validation: 0.8636\n",
      "Epoch: 0376 cost =  0.020876851 validation: 0.8693\n",
      "Epoch: 0377 cost =  0.020791618 validation: 0.8693\n",
      "Epoch: 0378 cost =  0.020855618 validation: 0.8750\n",
      "Epoch: 0379 cost =  0.020838875 validation: 0.8750\n",
      "Epoch: 0380 cost =  0.020818417 validation: 0.8693\n",
      "Epoch: 0381 cost =  0.020829280 validation: 0.8693\n",
      "Epoch: 0382 cost =  0.020814941 validation: 0.8693\n",
      "Epoch: 0383 cost =  0.020821943 validation: 0.8693\n",
      "Epoch: 0384 cost =  0.020807898 validation: 0.8693\n",
      "Epoch: 0385 cost =  0.020810542 validation: 0.8693\n",
      "Epoch: 0386 cost =  0.020801245 validation: 0.8693\n",
      "Epoch: 0387 cost =  0.020802308 validation: 0.8693\n",
      "Epoch: 0388 cost =  0.020799195 validation: 0.8693\n",
      "Epoch: 0389 cost =  0.020796118 validation: 0.8693\n",
      "Epoch: 0390 cost =  0.020788745 validation: 0.8693\n",
      "Epoch: 0391 cost =  0.020780323 validation: 0.8693\n",
      "Epoch: 0392 cost =  0.020789597 validation: 0.8693\n",
      "Epoch: 0393 cost =  0.020782648 validation: 0.8693\n",
      "Epoch: 0394 cost =  0.020786776 validation: 0.8693\n",
      "Epoch: 0395 cost =  0.020778398 validation: 0.8693\n",
      "Epoch: 0396 cost =  0.020776121 validation: 0.8693\n",
      "Epoch: 0397 cost =  0.020776746 validation: 0.8693\n",
      "Epoch: 0398 cost =  0.020805867 validation: 0.8693\n",
      "Epoch: 0399 cost =  0.020755050 validation: 0.8693\n",
      "Epoch: 0400 cost =  0.020798013 validation: 0.8693\n",
      "Epoch: 0401 cost =  0.020781693 validation: 0.8693\n",
      "Epoch: 0402 cost =  0.020781056 validation: 0.8693\n",
      "Epoch: 0403 cost =  0.020785778 validation: 0.8693\n",
      "Epoch: 0404 cost =  0.020778550 validation: 0.8693\n",
      "Epoch: 0405 cost =  0.020778885 validation: 0.8693\n",
      "Epoch: 0406 cost =  0.020783522 validation: 0.8693\n",
      "Epoch: 0407 cost =  0.020779586 validation: 0.8693\n",
      "Epoch: 0408 cost =  0.020766705 validation: 0.8693\n",
      "Epoch: 0409 cost =  0.020770850 validation: 0.8693\n",
      "Epoch: 0410 cost =  0.020766689 validation: 0.8693\n",
      "Epoch: 0411 cost =  0.020761511 validation: 0.8693\n",
      "Epoch: 0412 cost =  0.020770203 validation: 0.8693\n",
      "Epoch: 0413 cost =  0.020756697 validation: 0.8693\n",
      "Epoch: 0414 cost =  0.020762763 validation: 0.8693\n",
      "Epoch: 0415 cost =  0.020761137 validation: 0.8693\n",
      "Epoch: 0416 cost =  0.020764371 validation: 0.8693\n",
      "Epoch: 0417 cost =  0.020756395 validation: 0.8693\n",
      "Epoch: 0418 cost =  0.020749276 validation: 0.8693\n",
      "Epoch: 0419 cost =  0.020752644 validation: 0.8693\n",
      "Epoch: 0420 cost =  0.020749075 validation: 0.8693\n",
      "Epoch: 0421 cost =  0.020745322 validation: 0.8693\n",
      "Epoch: 0422 cost =  0.020765756 validation: 0.8693\n",
      "Epoch: 0423 cost =  0.020731237 validation: 0.8693\n",
      "Epoch: 0424 cost =  0.020754707 validation: 0.8693\n",
      "Epoch: 0425 cost =  0.020739226 validation: 0.8693\n",
      "Epoch: 0426 cost =  0.020745565 validation: 0.8693\n",
      "Epoch: 0427 cost =  0.020740141 validation: 0.8693\n",
      "Epoch: 0428 cost =  0.020733617 validation: 0.8693\n",
      "Epoch: 0429 cost =  0.020816239 validation: 0.8693\n",
      "Epoch: 0430 cost =  0.020760854 validation: 0.8693\n",
      "Epoch: 0431 cost =  0.020793601 validation: 0.8693\n",
      "Epoch: 0432 cost =  0.020803439 validation: 0.8693\n",
      "Epoch: 0433 cost =  0.020779271 validation: 0.8693\n",
      "Epoch: 0434 cost =  0.020799423 validation: 0.8693\n",
      "Epoch: 0435 cost =  0.020773480 validation: 0.8693\n",
      "Epoch: 0436 cost =  0.020789100 validation: 0.8693\n",
      "Epoch: 0437 cost =  0.020779811 validation: 0.8693\n",
      "Epoch: 0438 cost =  0.020770132 validation: 0.8693\n",
      "Epoch: 0439 cost =  0.020770866 validation: 0.8693\n",
      "Epoch: 0440 cost =  0.020768451 validation: 0.8693\n",
      "Epoch: 0441 cost =  0.020764225 validation: 0.8693\n",
      "Epoch: 0442 cost =  0.020765788 validation: 0.8693\n",
      "Epoch: 0443 cost =  0.020760148 validation: 0.8693\n",
      "Epoch: 0444 cost =  0.020756244 validation: 0.8693\n",
      "Epoch: 0445 cost =  0.020782888 validation: 0.8693\n",
      "Epoch: 0446 cost =  0.020768380 validation: 0.8693\n",
      "Epoch: 0447 cost =  0.020766157 validation: 0.8693\n",
      "Epoch: 0448 cost =  0.020770625 validation: 0.8693\n",
      "Epoch: 0449 cost =  0.020764600 validation: 0.8693\n",
      "Epoch: 0450 cost =  0.020806999 validation: 0.8693\n",
      "Epoch: 0451 cost =  0.020784672 validation: 0.8693\n",
      "Epoch: 0452 cost =  0.020782596 validation: 0.8693\n",
      "Epoch: 0453 cost =  0.020780446 validation: 0.8693\n",
      "Epoch: 0454 cost =  0.020771855 validation: 0.8693\n",
      "Epoch: 0455 cost =  0.020778308 validation: 0.8693\n",
      "Epoch: 0456 cost =  0.020758512 validation: 0.8693\n",
      "Epoch: 0457 cost =  0.020836542 validation: 0.8693\n",
      "Epoch: 0458 cost =  0.020766021 validation: 0.8693\n",
      "Epoch: 0459 cost =  0.020780720 validation: 0.8693\n",
      "Epoch: 0460 cost =  0.020790150 validation: 0.8693\n",
      "Epoch: 0461 cost =  0.020784168 validation: 0.8693\n",
      "Epoch: 0462 cost =  0.020782925 validation: 0.8693\n",
      "Epoch: 0463 cost =  0.020770597 validation: 0.8693\n",
      "Epoch: 0464 cost =  0.020777912 validation: 0.8693\n",
      "Epoch: 0465 cost =  0.020768753 validation: 0.8693\n",
      "Epoch: 0466 cost =  0.020768248 validation: 0.8693\n",
      "Epoch: 0467 cost =  0.020764502 validation: 0.8693\n",
      "Epoch: 0468 cost =  0.020765413 validation: 0.8693\n",
      "Epoch: 0469 cost =  0.020765268 validation: 0.8693\n",
      "Epoch: 0470 cost =  0.020766837 validation: 0.8636\n",
      "Epoch: 0471 cost =  0.020760036 validation: 0.8693\n",
      "Epoch: 0472 cost =  0.020755137 validation: 0.8693\n",
      "Epoch: 0473 cost =  0.020755175 validation: 0.8693\n",
      "Epoch: 0474 cost =  0.020748303 validation: 0.8693\n",
      "Epoch: 0475 cost =  0.020744494 validation: 0.8693\n",
      "Epoch: 0476 cost =  0.020751578 validation: 0.8693\n",
      "Epoch: 0477 cost =  0.020742938 validation: 0.8693\n",
      "Epoch: 0478 cost =  0.020742482 validation: 0.8693\n",
      "Epoch: 0479 cost =  0.020746128 validation: 0.8693\n",
      "Epoch: 0480 cost =  0.020737958 validation: 0.8693\n",
      "Epoch: 0481 cost =  0.020742243 validation: 0.8636\n",
      "Epoch: 0482 cost =  0.020738562 validation: 0.8636\n",
      "Epoch: 0483 cost =  0.020749440 validation: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0484 cost =  0.020767187 validation: 0.8693\n",
      "Epoch: 0485 cost =  0.020754980 validation: 0.8693\n",
      "Epoch: 0486 cost =  0.020752345 validation: 0.8636\n",
      "Epoch: 0487 cost =  0.020750845 validation: 0.8636\n",
      "Epoch: 0488 cost =  0.020746413 validation: 0.8636\n",
      "Epoch: 0489 cost =  0.020751640 validation: 0.8636\n",
      "Epoch: 0490 cost =  0.020739541 validation: 0.8636\n",
      "Epoch: 0491 cost =  0.020808878 validation: 0.8693\n",
      "Epoch: 0492 cost =  0.020774503 validation: 0.8636\n",
      "Epoch: 0493 cost =  0.020764625 validation: 0.8636\n",
      "Epoch: 0494 cost =  0.020784502 validation: 0.8636\n",
      "Epoch: 0495 cost =  0.020757615 validation: 0.8636\n",
      "Epoch: 0496 cost =  0.020772843 validation: 0.8636\n",
      "Epoch: 0497 cost =  0.020761348 validation: 0.8636\n",
      "Epoch: 0498 cost =  0.020762557 validation: 0.8636\n",
      "Epoch: 0499 cost =  0.020761311 validation: 0.8636\n",
      "Epoch: 0500 cost =  0.020769470 validation: 0.8636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 100\n",
    "counter = 0\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(y_train.shape[0] / batch_size)\n",
    "    for i in range(0, y_train.shape[0], batch_size):\n",
    "        sess.run(optimizer, feed_dict={learning_rate: 0.01})\n",
    "        feed_dict={X:X_train[i:i+batch_size,:,:,:], Y:y_train[i:i+batch_size,:]}\n",
    "        # run merged_summary\n",
    "        summary1, c, _ = sess.run([merged_summary, cost, optimizer], feed_dict=feed_dict)\n",
    "        # summary에 값 넣음\n",
    "        train_writer.add_summary(summary1, counter)\n",
    "        #cost_history = np.append(cost_history,cost)\n",
    "        avg_cost += c/total_batch\n",
    "        counter += 1\n",
    "    val_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test})\n",
    "    val_true = sess.run(tf.argmax(y_test,1))\n",
    "    accuracy = accuracy_score(val_pred, val_true)\n",
    "    print('Epoch:', '%04d' % (epoch+1), 'cost = ', '{:.9f}'.format(avg_cost),\n",
    "          'validation: {:.4f}'.format(accuracy))\n",
    "    # run performance summary\n",
    "    summary2 = sess.run(performance_summary, feed_dict={cost_ph:avg_cost, accuracy_ph:accuracy})\n",
    "    # add to the writer\n",
    "    train_writer.add_summary(summary2, counter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(logits,1),feed_dict={X: X_test})\n",
    "y_true = sess.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- mfcc\n",
    "- long frame (0.5sec), long window (0.25)\n",
    "- batch 100\n",
    "- rectangular filter size\n",
    "- epoch 2500\n",
    "- learning rate 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 어쩌다 잘된날...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.972\n",
      "Accuracy:  0.9715909090909091\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.98       113\n",
      "          1       0.95      0.97      0.96        63\n",
      "\n",
      "avg / total       0.97      0.97      0.97       176\n",
      "\n",
      "[[110   3]\n",
      " [  2  61]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xavier init 사용했을때\n",
    "- 197 에폭부터 accuracy 쭉 유지됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.966\n",
      "Accuracy:  0.9659090909090909\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97       113\n",
      "          1       0.98      0.92      0.95        63\n",
      "\n",
      "avg / total       0.97      0.97      0.97       176\n",
      "\n",
      "[[112   1]\n",
      " [  5  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xavier init 사용했을때 2\n",
    "- 473 에폭부터 accuracy 쭉 유지됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.875\n",
      "Accuracy:  0.875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.88      0.90       113\n",
      "          1       0.81      0.86      0.83        63\n",
      "\n",
      "avg / total       0.88      0.88      0.88       176\n",
      "\n",
      "[[100  13]\n",
      " [  9  54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more background data!\n",
    "- KSQ 에어콘 소리 포함...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 0.839\n",
      "Accuracy:  0.8385650224215246\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.88       158\n",
      "          1       0.71      0.75      0.73        65\n",
      "\n",
      "avg / total       0.84      0.84      0.84       223\n",
      "\n",
      "[[138  20]\n",
      " [ 16  49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
