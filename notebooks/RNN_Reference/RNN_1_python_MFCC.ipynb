{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "uav_path = '../../data/22050/loaded/*.*'\n",
    "uav_un_path = '../../data/22050/unloaded/*.*'\n",
    "none_path = '../../data/22050/none/*.*'\n",
    "\n",
    "uav_files = glob.glob(uav_path) + glob.glob(uav_un_path)\n",
    "none_files = glob.glob(none_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 개\t ../../data/22050/loaded\\LGgram_P2_loaded bck and forth.wav\n",
      "25 개\t ../../data/22050/none\\background_06_02_01.WAV\n"
     ]
    }
   ],
   "source": [
    "print(len(uav_files),'개\\t', uav_files[0])\n",
    "print(len(none_files), '개\\t',none_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The reason of why SR is 44100 is that the sample rate of above files is 44.1kbps\n",
    "\n",
    "a wav file sample has 884736. if sample is divided by sample rate, the value is time\n",
    "the time is fixed by 20.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uav_files = uav_files[:3]\n",
    "none_files = none_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12088678,)\n",
      "(2654208,)\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "uav_raw = load(uav_files)\n",
    "none_raw = load(none_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction \n",
    "## steps\n",
    "#### 1. Resampling \n",
    "#### 2. *VAD*( Voice Activity Detection)\n",
    "#### 3. Maybe padding with 0 to make signals be equal length\n",
    "#### 4. Log spectrogram (or *MFCC*, or *PLP*)\n",
    "#### 5. Features normalization with *mean* and *std*\n",
    "#### 6. Stacking of a given number of frames to get temporal information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resampling\n",
    "\n",
    "if you see the graph, there are few at high frequency. this is mean that data is big but it's no useless. so To small the data, do Resampling. In general, use 0~8000Hz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAD\n",
    "\n",
    "Sometimes, Files have silence. It is not necessary. So, We need to find sound of Drone except silence.\n",
    "\n",
    "But, Not yet implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. padding with 0 to make signals be equal length\n",
    "\n",
    "If we have a lot of sound files, we need to pad some datas. But These files's time is longger than 1 second. So It dosn't need to pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Log spectrogram (or MFCC, or PLP)\n",
    "\n",
    "The upper picture is resampled data. \n",
    "The lower picture is original data.\n",
    "\n",
    "In MFCC Feature, There is no big difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "#returns mfcc features with mean and standard deviation along time\n",
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=22050, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc* n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0]* mfcc_slice.shape[1]))\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "def mfcc(raw, chunk_size=8192, sr=44100, n_mfcc=13):\n",
    "    mfcc = np.empty((13, 0))\n",
    "    for i in range(0, len(raw), chunk_size):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc = np.hstack((mfcc, mfcc_slice))\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25086,)\n",
      "(5508,)\n",
      "(30594, 13) (30594,)\n",
      "(30594, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "mfcc_uav, y_uav = mfcc4(uav_raw, 1)\n",
    "print(mfcc_uav.shape, y_uav.shape)\n",
    "mfcc_none, y_none = mfcc4(none_raw, 0)\n",
    "print(mfcc_none.shape, y_none.shape)\n",
    "'''\n",
    "mfcc_uav = mfcc(uav_raw)\n",
    "mfcc_none = mfcc(none_raw)\n",
    "# or should we give one label to one chunk?\n",
    "y_uav = np.ones(mfcc_uav.shape[1], dtype=int)\n",
    "y_none =np.zeros(mfcc_none.shape[1], dtype=int)\n",
    "\n",
    "print(y_uav.shape)\n",
    "print(y_none.shape)\n",
    "X = np.hstack((mfcc_uav, mfcc_none)).T\n",
    "y = np.hstack((y_uav, y_none))\n",
    "print(X.shape, y.shape)\n",
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmfcc_uav_list = mfcc_uav.tolist()\\nmfcc_uav_list = mfcc_uav_list\\nfig = plt.figure(figsize=(15,9))\\nax = fig.add_subplot(1,1,1)\\nax.plot(np.linspace(0,len(mfcc_uav_list), len(mfcc_uav_list)),mfcc_uav_list)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mfcc_uav_list = mfcc_uav.tolist()\n",
    "mfcc_uav_list = mfcc_uav_list\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.linspace(0,len(mfcc_uav_list), len(mfcc_uav_list)),mfcc_uav_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Features normalization with *mean* and *std*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stacking of a given number of frames to get temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = np.concatenate((mfcc_uav, mfcc_none), axis=0)\\nY = np.hstack((y_uav, y_none))\\nprint(X.shape, Y.shape)\\nX = np.reshape(X,(X.shape[0],-1))# 선범 \\n\\nn_labels = Y.shape[0]\\nn_unique_labels = 2\\ny_encoded = np.zeros((n_labels, n_unique_labels))\\ny_encoded[np.arange(n_labels), Y] = 1\\nprint(y_encoded.shape)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X = np.concatenate((mfcc_uav, mfcc_none), axis=0)\n",
    "Y = np.hstack((y_uav, y_none))\n",
    "print(X.shape, Y.shape)\n",
    "X = np.reshape(X,(X.shape[0],-1))# 선범 \n",
    "\n",
    "n_labels = Y.shape[0]\n",
    "n_unique_labels = 2\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), Y] = 1\n",
    "print(y_encoded.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "(30594, 13) (30594, 2)\n"
     ]
    }
   ],
   "source": [
    "dataX = X\n",
    "dataY = y_encoded\n",
    "print(y_encoded)\n",
    "print(dataX.shape, dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30565, 30, 13) (30565, 2)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 30 #layer\n",
    "X_hot_list= []\n",
    "#Y_hot = dataY[seq_length-1:].reshape(len(dataY[seq_length-1:]), 1)\n",
    "Y_hot_tmp = dataY[seq_length-1:]\n",
    "\n",
    "for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "    _x = dataX[i:i + seq_length]\n",
    "    #if i<10:\n",
    "        #print(_x, \"->\", Y_hot_tmp[i])\n",
    "    X_hot_list.append(_x)\n",
    "\n",
    "X_hot = np.array(X_hot_list[:])\n",
    "Y_hot= Y_hot_tmp.reshape((len(Y_hot_tmp),2))\n",
    "print(X_hot.shape, Y_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [11, 12, 13]\n",
      "[4, 5, 6] [14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self,X,Y,BatchSize):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.len = len(Y)\n",
    "        self.bs = BatchSize\n",
    "        self.bs_i = 0\n",
    "    def getBatchData(self):\n",
    "        s = self.bs_i\n",
    "        e = self.bs_i + self.bs\n",
    "        if e> self.len:\n",
    "            e -= self.len\n",
    "            result =  np.vstack((self.X[s:],self.X[:e])), np.vstack((self.Y[s:],self.Y[:e]))\n",
    "        else:\n",
    "            result =  self.X[s:e], self.Y[s:e]\n",
    "            \n",
    "        self.bs_i = e\n",
    "        return result\n",
    "dataX = [1,2,3,4,5,6,7,8]\n",
    "dataY = [11,12,13,14,15,16,17,18]\n",
    "D = Data(dataX, dataY,3)\n",
    "x, y = D.getBatchData()\n",
    "print(x,y)\n",
    "x, y = D.getBatchData()\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_dim = 256\\nX_train = np.zeros(shape=[0,9,X_dim],dtype=float)\\ny_train = np.zeros(shape=[0,n_unique_labels],dtype=float)\\nX_test = np.zeros(shape=[0,9,X_dim],dtype=float)\\ny_test = np.zeros(shape=[0,n_unique_labels],dtype=float)\\n\\nsplit_rate = 0.9\\nnone_len = len(y_none)\\nuav_len = len(X_hot) - none_len\\nprint('uav_len, none_len', uav_len,none_len)\\n\\ntrain_size = int(uav_len * split_rate)\\ntest_size = uav_len - train_size\\nbase = 0\\nprint('train_uav, test_uav',train_size,test_size)\\n\\nX_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+test_size])\\ny_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+test_size])\\nprint(X_tr.shape,X_te.shape)\\nprint(y_tr.shape,y_te.shape)\\n\\nX_train = np.vstack((X_train,X_tr))\\nX_test= np.vstack((X_test,X_te))\\ny_train= np.vstack((y_train,y_tr))\\ny_test= np.vstack((y_test,y_te))\\n\\ntrain_size = int(none_len * split_rate)\\ntest_size = none_len - train_size\\nbase = uav_len\\nprint('none',train_size,test_size)\\n\\nX_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+none_len])\\ny_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+none_len])\\nprint(X_tr.shape,X_te.shape)\\nprint(y_tr.shape,y_te.shape)\\n\\nprint(base+none_len)\\nX_train = np.vstack((X_train,X_tr))\\nX_test= np.vstack((X_test,X_te))\\ny_train= np.vstack((y_train,y_tr))\\ny_test= np.vstack((y_test,y_te))\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_dim = 256\n",
    "X_train = np.zeros(shape=[0,9,X_dim],dtype=float)\n",
    "y_train = np.zeros(shape=[0,n_unique_labels],dtype=float)\n",
    "X_test = np.zeros(shape=[0,9,X_dim],dtype=float)\n",
    "y_test = np.zeros(shape=[0,n_unique_labels],dtype=float)\n",
    "\n",
    "split_rate = 0.9\n",
    "none_len = len(y_none)\n",
    "uav_len = len(X_hot) - none_len\n",
    "print('uav_len, none_len', uav_len,none_len)\n",
    "\n",
    "train_size = int(uav_len * split_rate)\n",
    "test_size = uav_len - train_size\n",
    "base = 0\n",
    "print('train_uav, test_uav',train_size,test_size)\n",
    "\n",
    "X_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+test_size])\n",
    "y_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+test_size])\n",
    "print(X_tr.shape,X_te.shape)\n",
    "print(y_tr.shape,y_te.shape)\n",
    "\n",
    "X_train = np.vstack((X_train,X_tr))\n",
    "X_test= np.vstack((X_test,X_te))\n",
    "y_train= np.vstack((y_train,y_tr))\n",
    "y_test= np.vstack((y_test,y_te))\n",
    "\n",
    "train_size = int(none_len * split_rate)\n",
    "test_size = none_len - train_size\n",
    "base = uav_len\n",
    "print('none',train_size,test_size)\n",
    "\n",
    "X_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+none_len])\n",
    "y_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+none_len])\n",
    "print(X_tr.shape,X_te.shape)\n",
    "print(y_tr.shape,y_te.shape)\n",
    "\n",
    "print(base+none_len)\n",
    "X_train = np.vstack((X_train,X_tr))\n",
    "X_test= np.vstack((X_test,X_te))\n",
    "y_train= np.vstack((y_train,y_tr))\n",
    "y_test= np.vstack((y_test,y_te))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_hot, Y_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "traindata = Data(X_train,y_train,batch_size)\n",
    "testdata = Data(X_test,y_test,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24452, 30, 13) (6113, 30, 13)\n",
      "(24452, 2) (6113, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnp.save('../data/Xy/X_train2', X_train)\\nnp.save('../data/Xy/X_test2', X_test)\\nnp.save('../data/Xy/y_train2', y_train)\\nnp.save('../data/Xy/y_test2', y_test)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "np.save('../data/Xy/X_train2', X_train)\n",
    "np.save('../data/Xy/X_test2', X_test)\n",
    "np.save('../data/Xy/y_train2', y_train)\n",
    "np.save('../data/Xy/y_test2', y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = np.load('../data/Xy/X_train2.npy')\\nX_test = np.load('../data/Xy/X_test2.npy')\\ny_train = np.load('../data/Xy/y_train2.npy')\\ny_test = np.load('../data/Xy/y_test2.npy')\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = np.load('../data/Xy/X_train2.npy')\n",
    "X_test = np.load('../data/Xy/X_test2.npy')\n",
    "y_train = np.load('../data/Xy/y_train2.npy')\n",
    "y_test = np.load('../data/Xy/y_test2.npy')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size\n",
    "num_classes = 13            #분류할 사전의 크기 \n",
    "\n",
    "learning_rate = 0.01\n",
    "sequence_length = seq_length #9         \n",
    "\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, sequence_length,num_classes], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim], name=\"Y\")\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=num_classes, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell]*3, state_is_tuple= True)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X,initial_state=initial_state,dtype=tf.float32)\n",
    "\n",
    "dense1 = tf.contrib.layers.fully_connected(outputs[:,-1], output_dim, activation_fn=None)\n",
    "dense2 = tf.layers.dense(inputs=dense1, units=output_dim, activation=tf.nn.relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred= tf.layers.dense(inputs=dense2, units=output_dim)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Y_pred, labels=Y))\n",
    "lr = tf.placeholder(tf.float32,shape=(), name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(lr).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.07648289e+02,  2.03488724e+02, -1.14136238e+02,\n",
       "         9.91313003e+01, -3.74261068e+01,  1.00363538e+01,\n",
       "         3.12128010e+01, -1.02043347e+01,  2.71966987e+01,\n",
       "        -1.38880330e+01,  1.06058939e+01, -6.24269815e+00,\n",
       "        -2.43524508e+00],\n",
       "       [-2.02715856e+02,  2.05642662e+02, -1.15350295e+02,\n",
       "         9.33696292e+01, -4.35500252e+01,  9.24127689e+00,\n",
       "         2.41659329e+01, -1.79198746e+01,  2.41261692e+01,\n",
       "        -1.47316070e+01,  1.45228664e+01,  4.66049613e-01,\n",
       "         4.76957769e+00],\n",
       "       [-2.02733305e+02,  2.08994114e+02, -1.14728475e+02,\n",
       "         9.20522347e+01, -4.29219713e+01,  3.79166883e+00,\n",
       "         1.88983680e+01, -1.87710572e+01,  2.50122544e+01,\n",
       "        -1.30369161e+01,  1.62333415e+01, -1.30782291e+00,\n",
       "        -3.62533075e+00],\n",
       "       [-2.03313368e+02,  2.07521572e+02, -1.13799065e+02,\n",
       "         9.46535998e+01, -4.27451970e+01,  4.02028044e+00,\n",
       "         1.85615647e+01, -1.83741074e+01,  2.61484307e+01,\n",
       "        -1.57537060e+01,  1.35994359e+01, -5.03899088e+00,\n",
       "        -9.18179212e+00],\n",
       "       [-2.02740222e+02,  2.06169742e+02, -1.14906951e+02,\n",
       "         9.58140931e+01, -4.12278574e+01,  8.45014732e+00,\n",
       "         2.20098345e+01, -1.71046322e+01,  3.20270870e+01,\n",
       "        -9.92170331e+00,  1.69293538e+01,  1.71038778e+00,\n",
       "        -1.75491216e+00],\n",
       "       [-1.84015089e+02,  1.80414529e+02, -8.77240007e+01,\n",
       "         8.59194258e+01, -3.14328639e+01,  7.92367994e+00,\n",
       "         1.71925771e+01, -1.47531883e+01,  2.06650180e+01,\n",
       "         4.75279766e+00,  1.71387311e+01,  9.19140228e+00,\n",
       "         3.11218957e+00],\n",
       "       [-1.75799000e+02,  1.63269499e+02, -7.04694643e+01,\n",
       "         7.71030650e+01, -2.55655809e+01,  7.32478887e+00,\n",
       "         1.59820683e+01, -1.57315416e+01,  9.98060905e+00,\n",
       "         1.69974323e+00,  1.62496363e+01,  1.39544875e+01,\n",
       "         5.85022756e+00],\n",
       "       [-2.12339193e+02,  1.96213684e+02, -1.00327396e+02,\n",
       "         8.74959072e+01, -5.32630694e+01, -4.32673990e+00,\n",
       "         1.79747086e+01, -1.61838698e+01,  2.31379444e+01,\n",
       "        -7.94465053e+00,  2.20855757e+01,  2.25081685e+00,\n",
       "        -1.62367806e+00],\n",
       "       [-1.99559569e+02,  2.06699941e+02, -1.02551049e+02,\n",
       "         9.11995396e+01, -4.10678483e+01,  3.87745013e+00,\n",
       "         1.93515882e+01, -2.02375527e+01,  2.49146191e+01,\n",
       "        -7.88570655e+00,  1.96221551e+01,  2.77651620e+00,\n",
       "        -2.96488731e+00],\n",
       "       [-2.00389058e+02,  2.05696174e+02, -1.04166223e+02,\n",
       "         9.03967017e+01, -3.94341697e+01,  7.37188460e+00,\n",
       "         2.16826713e+01, -2.03614197e+01,  2.76988046e+01,\n",
       "        -6.84456694e+00,  1.44172677e+01, -1.10713561e+00,\n",
       "        -1.71152394e+00],\n",
       "       [-2.01973240e+02,  2.03223395e+02, -1.06777738e+02,\n",
       "         8.77158015e+01, -4.02598171e+01,  8.64132145e+00,\n",
       "         2.19292628e+01, -2.27490141e+01,  2.13059669e+01,\n",
       "        -1.17393094e+01,  1.54185072e+01,  4.64170148e-02,\n",
       "        -3.15316023e+00],\n",
       "       [-2.06147690e+02,  1.98244012e+02, -1.05961015e+02,\n",
       "         9.49052572e+01, -3.27105395e+01,  1.05750415e+01,\n",
       "         1.84674852e+01, -2.55341719e+01,  1.83692739e+01,\n",
       "        -1.21596305e+01,  2.02988056e+01,  3.12035015e+00,\n",
       "        -5.32841495e+00],\n",
       "       [-2.05481563e+02,  1.99331839e+02, -1.01356633e+02,\n",
       "         1.00744012e+02, -3.36582081e+01,  5.22461125e+00,\n",
       "         1.71369622e+01, -2.04297071e+01,  2.36795749e+01,\n",
       "        -1.21761499e+01,  1.91824285e+01,  4.22493967e+00,\n",
       "        -4.46046000e+00],\n",
       "       [-2.04703543e+02,  2.00998149e+02, -1.01396980e+02,\n",
       "         9.67199637e+01, -3.93179394e+01,  1.84381523e+00,\n",
       "         1.72853656e+01, -2.01536983e+01,  2.35192213e+01,\n",
       "        -1.22942638e+01,  1.77501343e+01,  3.67781384e+00,\n",
       "        -2.79080579e+00],\n",
       "       [-2.06707086e+02,  1.97431667e+02, -1.05560770e+02,\n",
       "         9.37460120e+01, -4.01884441e+01,  2.58188866e+00,\n",
       "         1.87273005e+01, -1.89940854e+01,  2.51659320e+01,\n",
       "        -9.00363633e+00,  1.78872634e+01, -3.16834619e-01,\n",
       "        -3.77113735e+00],\n",
       "       [-2.01960380e+02,  2.00678133e+02, -1.10150549e+02,\n",
       "         8.89434894e+01, -4.05327845e+01,  2.15771549e+00,\n",
       "         1.88297095e+01, -2.03728730e+01,  2.28691982e+01,\n",
       "        -8.82208937e+00,  1.71733600e+01, -5.31909467e+00,\n",
       "        -1.02948569e+01],\n",
       "       [-1.99759468e+02,  2.03174944e+02, -1.05745290e+02,\n",
       "         9.25600620e+01, -3.96607778e+01,  5.95691617e+00,\n",
       "         2.23500596e+01, -1.85739041e+01,  2.24059191e+01,\n",
       "        -1.22988553e+01,  1.78917060e+01, -5.13328494e+00,\n",
       "        -1.18694488e+01],\n",
       "       [-2.05331194e+02,  1.96427211e+02, -1.05417813e+02,\n",
       "         9.72122831e+01, -3.30023751e+01,  1.56149454e+01,\n",
       "         2.55734200e+01, -1.77091295e+01,  2.25936371e+01,\n",
       "        -1.86579201e+01,  1.28694263e+01, -4.67067501e+00,\n",
       "        -6.16426895e+00],\n",
       "       [-2.11071954e+02,  1.91621849e+02, -1.11491251e+02,\n",
       "         9.23476999e+01, -3.14901443e+01,  1.43382338e+01,\n",
       "         2.41211833e+01, -1.62590970e+01,  2.60514649e+01,\n",
       "        -1.58195061e+01,  1.11133838e+01, -4.00592321e+00,\n",
       "        -5.03194500e+00],\n",
       "       [-2.09430928e+02,  1.99291430e+02, -1.01734913e+02,\n",
       "         9.58433772e+01, -3.05994874e+01,  1.16672422e+01,\n",
       "         2.10936720e+01, -1.16164285e+01,  3.28449938e+01,\n",
       "        -1.33793991e+01,  1.08594200e+01, -1.27108068e+00,\n",
       "        -2.98048757e+00],\n",
       "       [-2.06098716e+02,  1.98218314e+02, -1.03041452e+02,\n",
       "         9.76229339e+01, -3.44593836e+01,  1.00058629e+01,\n",
       "         2.33663968e+01, -1.13520450e+01,  3.33345032e+01,\n",
       "        -1.38958596e+01,  8.42893103e+00, -1.47098518e+00,\n",
       "         3.23693702e+00],\n",
       "       [-2.01082611e+02,  2.02493472e+02, -1.04839770e+02,\n",
       "         9.66253072e+01, -3.32696393e+01,  1.08593855e+01,\n",
       "         2.53125428e+01, -1.47461254e+01,  3.01392968e+01,\n",
       "        -9.07256984e+00,  1.62293888e+01,  3.29036613e+00,\n",
       "         2.53830728e+00],\n",
       "       [-2.04897285e+02,  1.99134018e+02, -1.06753764e+02,\n",
       "         9.78868806e+01, -2.73537951e+01,  1.51984324e+01,\n",
       "         2.65285263e+01, -1.78488486e+01,  2.44254908e+01,\n",
       "        -9.31807685e+00,  2.10768280e+01,  8.21709017e+00,\n",
       "         3.56118774e+00],\n",
       "       [-2.13757354e+02,  1.85554489e+02, -1.09968537e+02,\n",
       "         9.51640977e+01, -2.83820679e+01,  1.55045980e+01,\n",
       "         2.18996641e+01, -1.29757776e+01,  2.36552140e+01,\n",
       "        -8.32369019e+00,  2.13218266e+01,  5.17943234e+00,\n",
       "         1.72377142e+00],\n",
       "       [-1.78765902e+02,  1.44655752e+02, -5.18008561e+01,\n",
       "         7.89273613e+01, -1.03431903e+01,  3.63797938e+00,\n",
       "         6.07354505e+00, -4.25461086e+00,  7.60210156e+00,\n",
       "         1.24032455e+00,  1.01407806e+01,  3.72027354e+00,\n",
       "        -2.27000207e+00],\n",
       "       [-1.81044037e+02,  1.66052335e+02, -7.37157317e+01,\n",
       "         7.87883754e+01, -1.93775904e+01,  1.03640241e+01,\n",
       "         1.10653695e+01, -8.90057970e+00,  1.11202018e+01,\n",
       "         8.04791571e-01,  1.34878005e+01,  7.88236089e+00,\n",
       "         2.77620213e+00],\n",
       "       [-2.09709118e+02,  2.03894080e+02, -1.12665182e+02,\n",
       "         9.77326715e+01, -3.49325251e+01,  8.81680613e+00,\n",
       "         2.36133320e+01, -1.91506222e+01,  2.39543287e+01,\n",
       "        -1.27593685e+01,  1.60489676e+01,  2.86354866e+00,\n",
       "         2.98313562e+00],\n",
       "       [-2.17924101e+02,  1.94248450e+02, -1.17065027e+02,\n",
       "         9.76891247e+01, -3.30820139e+01,  1.07324224e+01,\n",
       "         2.76826357e+01, -1.13352176e+01,  3.03560395e+01,\n",
       "        -8.84234647e+00,  1.60369878e+01, -2.02184301e+00,\n",
       "        -2.46634025e+00],\n",
       "       [-2.10424519e+02,  2.02354433e+02, -1.12431291e+02,\n",
       "         9.65442121e+01, -3.88253578e+01,  6.98012659e+00,\n",
       "         2.60368657e+01, -1.20055865e+01,  3.02991905e+01,\n",
       "        -1.02885742e+01,  1.05220760e+01, -7.23610074e+00,\n",
       "        -5.47872688e+00],\n",
       "       [-2.07219434e+02,  2.03840491e+02, -1.11308932e+02,\n",
       "         9.85260500e+01, -3.90809508e+01,  1.01193308e+01,\n",
       "         2.72050195e+01, -1.89841770e+01,  2.46448470e+01,\n",
       "        -1.23134246e+01,  9.49876328e+00, -7.11166944e+00,\n",
       "        -3.56131062e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(traindata.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x, y = traindata.getBatchData()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 0.6880413293838501\n",
      "[step: 1] loss: 0.5679805278778076\n",
      "[step: 2] loss: 0.32920777797698975\n",
      "[step: 3] loss: 0.19134145975112915\n",
      "[step: 4] loss: 0.12670046091079712\n",
      "[step: 5] loss: 0.08534082770347595\n",
      "[step: 6] loss: 0.058573655784130096\n",
      "[step: 7] loss: 0.05463520064949989\n",
      "[step: 8] loss: 0.04657755047082901\n",
      "[step: 9] loss: 0.025226633995771408\n",
      "[step: 10] loss: 0.03209063410758972\n",
      "[step: 11] loss: 0.056330516934394836\n",
      "[step: 12] loss: 0.895047664642334\n",
      "[step: 13] loss: 0.022566981613636017\n",
      "[step: 14] loss: 0.006139074917882681\n",
      "[step: 15] loss: 0.020556826144456863\n",
      "[step: 16] loss: 0.003959115594625473\n",
      "[step: 17] loss: 0.002975922543555498\n",
      "[step: 18] loss: 0.0020318259485065937\n",
      "[step: 19] loss: 0.0017800116911530495\n",
      "[step: 20] loss: 0.001622575568035245\n",
      "[step: 21] loss: 0.01468678005039692\n",
      "[step: 22] loss: 0.0011953619541600347\n",
      "[step: 23] loss: 0.020903101190924644\n",
      "[step: 24] loss: 0.0011080590775236487\n",
      "[step: 25] loss: 0.0010406147921457887\n",
      "[step: 26] loss: 0.0010299086570739746\n",
      "[step: 27] loss: 0.0010033880826085806\n",
      "[step: 28] loss: 0.000908000161871314\n",
      "[step: 29] loss: 0.0009242313099093735\n",
      "[step: 30] loss: 0.0008916559163480997\n",
      "[step: 31] loss: 0.0008887991425581276\n",
      "[step: 32] loss: 0.0008901655673980713\n",
      "[step: 33] loss: 0.014846614561975002\n",
      "[step: 34] loss: 0.0009007541229948401\n",
      "[step: 35] loss: 0.0008839136571623385\n",
      "[step: 36] loss: 0.0009088916704058647\n",
      "[step: 37] loss: 0.0015768478624522686\n",
      "[step: 38] loss: 0.0009075007401406765\n",
      "[step: 39] loss: 0.0009135202853940427\n",
      "[step: 40] loss: 0.014247812330722809\n",
      "[step: 41] loss: 0.0009022048907354474\n",
      "[step: 42] loss: 0.0008911606855690479\n",
      "[step: 43] loss: 0.005907455459237099\n",
      "[step: 44] loss: 0.010491631925106049\n",
      "[step: 45] loss: 0.0008812039159238338\n",
      "[step: 46] loss: 0.0008472696645185351\n",
      "[step: 47] loss: 0.0018487484194338322\n",
      "[step: 48] loss: 0.0008210146334022284\n",
      "[step: 49] loss: 0.008126449771225452\n",
      "Test accuracy: 0.915\n",
      "[step: 0] loss: 0.0008105241577140987\n",
      "[step: 1] loss: 0.0007928019622340798\n",
      "[step: 2] loss: 0.000779361929744482\n",
      "[step: 3] loss: 0.0007793250842951238\n",
      "[step: 4] loss: 0.014572512358427048\n",
      "[step: 5] loss: 0.0007873771828599274\n",
      "[step: 6] loss: 0.009409592486917973\n",
      "[step: 7] loss: 0.000765589065849781\n",
      "[step: 8] loss: 0.000767611141782254\n",
      "[step: 9] loss: 0.0007668556063435972\n",
      "[step: 10] loss: 0.0034447654616087675\n",
      "[step: 11] loss: 0.0007231909548863769\n",
      "[step: 12] loss: 0.0007432298152707517\n",
      "[step: 13] loss: 0.0007198205566965044\n",
      "[step: 14] loss: 0.0007307968917302787\n",
      "[step: 15] loss: 0.0007064066594466567\n",
      "[step: 16] loss: 0.000719717179890722\n",
      "[step: 17] loss: 0.000720720796380192\n",
      "[step: 18] loss: 0.000710305932443589\n",
      "[step: 19] loss: 0.0006912027020007372\n",
      "[step: 20] loss: 0.0006746667786501348\n",
      "[step: 21] loss: 0.0006866854964755476\n",
      "[step: 22] loss: 0.013629287481307983\n",
      "[step: 23] loss: 0.0006552610429935157\n",
      "[step: 24] loss: 0.0006488569779321551\n",
      "[step: 25] loss: 0.0006506534991785884\n",
      "[step: 26] loss: 0.0006263248506002128\n",
      "[step: 27] loss: 0.0006338687380775809\n",
      "[step: 28] loss: 0.0006266047130338848\n",
      "[step: 29] loss: 0.000611104303970933\n",
      "[step: 30] loss: 0.0006032899254933\n",
      "[step: 31] loss: 0.015206986106932163\n",
      "[step: 32] loss: 0.0005962222348898649\n",
      "[step: 33] loss: 0.000592520460486412\n",
      "[step: 34] loss: 0.0005620103911496699\n",
      "[step: 35] loss: 0.0005780122592113912\n",
      "[step: 36] loss: 0.0005785833927802742\n",
      "[step: 37] loss: 0.0005580059951171279\n",
      "[step: 38] loss: 0.0005546973552554846\n",
      "[step: 39] loss: 0.014493172988295555\n",
      "[step: 40] loss: 0.0005329695413820446\n",
      "[step: 41] loss: 0.0005276364972814918\n",
      "[step: 42] loss: 0.0005291025736369193\n",
      "[step: 43] loss: 0.009862758219242096\n",
      "[step: 44] loss: 0.0005295771406963468\n",
      "[step: 45] loss: 0.0005155227845534682\n",
      "[step: 46] loss: 0.0005472316988743842\n",
      "[step: 47] loss: 0.0005096621462143958\n",
      "[step: 48] loss: 0.003275011433288455\n",
      "[step: 49] loss: 0.0005110161728225648\n",
      "Test accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "step_loss = 999999.0\n",
    "model_path = '../../models/RNN/my_RNN_model_S9_10'\n",
    "saver = tf.train.Saver()\n",
    "training_epochs = 50\n",
    "# Training step\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "for learning_rate in [0.02,0.01]:\n",
    "    test_acc = []\n",
    "    feed = {lr:learning_rate}\n",
    "    for i in range(training_epochs):\n",
    "        x,y = traindata.getBatchData()\n",
    "        feed[X], feed[Y] = x, y\n",
    "        step_loss_prev = step_loss\n",
    "        _, step_loss = sess.run([train, cost], feed_dict=feed)\n",
    "        cost_history = np.append(cost_history,step_loss)\n",
    "        \n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "        #batch_acc, test_state = sess.run([loss, _states], feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.3f}\".format(1.0-np.mean(cost_history)))\n",
    "\n",
    "saver.save(sess, model_path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../models/RNN/my_RNN_model_S9_10\n",
      "(500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver.restore(sess, model_path)\n",
    "x , y = testdata.getBatchData()\n",
    "y_pred = sess.run(tf.argmax(Y_pred,1),feed_dict={X: x})\n",
    "y_true = sess.run(tf.argmax(y,1))\n",
    "print(y_pred.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 1.0\n",
      "Accuracy:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        97\n",
      "          1       1.00      1.00      1.00       403\n",
      "\n",
      "avg / total       1.00      1.00      1.00       500\n",
      "\n",
      "[[ 97   0]\n",
      " [  0 403]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\") \n",
    "plt.axis([0,len(cost_history),0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File ../models/RNN/my_RNN_model_S9_40.meta does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9256aef6a54d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path_f\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                        \"execution is enabled.\")\n\u001b[0;32m   1946\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m     \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_meta_graph_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_or_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mread_meta_graph_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    630\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetaGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File %s does not exist.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m   \u001b[1;31m# First try to read it as a binary file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   \u001b[0mfile_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File ../models/RNN/my_RNN_model_S9_40.meta does not exist."
     ]
    }
   ],
   "source": [
    "model_path_f = '../models/RNN/'\n",
    "filename = 'my_RNN_model_S9_40.meta'\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loader = tf.train.import_meta_graph(model_path_f+filename)\n",
    "loader.restore(sess, tf.train.latest_checkpoint(model_path_f))\n",
    "\n",
    "SR = 22050\n",
    "####\n",
    "justone = True\n",
    "\n",
    "while(justone):\n",
    "    justone = False\n",
    "    #print(\"start to record the audio.\")\n",
    "    '''\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    #print(\"Recording finished.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    '''\n",
    "    ####\n",
    "    filename1 = '../data/phantom/JUNE_01_PHANTOMS/wavs/22050/WSU_P2_LOADED_BACK_AND_FORTH.wav'\n",
    "    filename2 = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/canopy_heavy_wind.wav'\n",
    "    \n",
    "    sample, sample_rate = librosa.load(filename1,SR)\n",
    "    print(sample.shape)\n",
    "    \n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(sample, sample_rate)    \n",
    "    #showFreqTime([[sample, filename1, SR]])  \n",
    "\n",
    "    spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    dataX = spectrogram\n",
    "    #print(dataX.shape)\n",
    "    #print('delta shape:',dataX.shape)\n",
    "\n",
    "    X_hot_list= []\n",
    "    #print(dataX.shape[0] - seq_length+1)\n",
    "    for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "        _x = dataX[i:i + seq_length]\n",
    "        X_hot_list.append(_x)\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    #print(X_hot[0])\n",
    "    #print('\\n\\n\\n')\n",
    "    y_pred = sess.run(Y_pred,feed_dict={X: X_hot})\n",
    "    #y_pred[y_pred<0.5] = 0\n",
    "    #y_pred[y_pred>=0.5] = 1\n",
    "    print(y_pred[20:30] )\n",
    "    y_true = np.ones(shape=[y_pred.shape[0]])\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    \n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print(\"F-Score:\", round(f,3))\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    '''\n",
    "    if y_pred[0] == 1:\n",
    "        print('The sound is Drone')\n",
    "    else :\n",
    "        print('THe sound isn\\'t Drone')\n",
    "    '''\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
