{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "uav_path = '../data/44100/Unloaded/*.*'\n",
    "loaded_path = '../data/44100/Loaded/*.*'\n",
    "none_path = '../data/44100/Background/*.*'\n",
    "\n",
    "uav_files = glob.glob(uav_path)\n",
    "loaded_files = glob.glob(loaded_path)\n",
    "none_files = glob.glob(none_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 개\t ../data/44100/Unloaded\\P1_stationary.wav\n",
      "10 개\t ../data/44100/Loaded\\test_1532717717-loaded.wav\n",
      "50 개\t ../data/44100/Background\\background_06_02_01.wav\n"
     ]
    }
   ],
   "source": [
    "print(len(uav_files),'개\\t', uav_files[0])\n",
    "print(len(uav_files),'개\\t', loaded_files[0])\n",
    "print(len(none_files), '개\\t',none_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The reason of why SR is 44100 is that the sample rate of above files is 44.1kbps\n",
    "\n",
    "a wav file sample has 884736. if sample is divided by sample rate, the value is time\n",
    "the time is fixed by 20.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34496499,)\n",
      "(16942106,)\n",
      "(81385951,)\n"
     ]
    }
   ],
   "source": [
    "uav_raw = load(uav_files)\n",
    "loaded_raw = load(loaded_files)\n",
    "none_raw = load(none_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction \n",
    "## steps\n",
    "#### 1. Resampling \n",
    "#### 2. *VAD*( Voice Activity Detection)\n",
    "#### 3. Maybe padding with 0 to make signals be equal length\n",
    "#### 4. Log spectrogram (or *MFCC*, or *PLP*)\n",
    "#### 5. Features normalization with *mean* and *std*\n",
    "#### 6. Stacking of a given number of frames to get temporal information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resampling\n",
    "\n",
    "if you see the graph, there are few at high frequency. this is mean that data is big but it's no useless. so To small the data, do Resampling. In general, use 0~8000Hz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAD\n",
    "\n",
    "Sometimes, Files have silence. It is not necessary. So, We need to find sound of Drone except silence.\n",
    "\n",
    "But, Not yet implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. padding with 0 to make signals be equal length\n",
    "\n",
    "If we have a lot of sound files, we need to pad some datas. But These files's time is longger than 1 second. So It dosn't need to pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Log spectrogram (or MFCC, or PLP)\n",
    "\n",
    "The upper picture is resampled data. \n",
    "The lower picture is original data.\n",
    "\n",
    "In MFCC Feature, There is no big difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "#returns mfcc features with mean and standard deviation along time\n",
    "N_MFCC = 20\n",
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=44100, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc* n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0]* mfcc_slice.shape[1]))\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "def mfcc(raw, chunk_size=8192, sr=44100, n_mfcc=N_MFCC):\n",
    "    mfcc = np.empty((N_MFCC, 0))\n",
    "    for i in range(0, len(raw), chunk_size):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc = np.hstack((mfcc, mfcc_slice))\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "mfcc_uav, y_uav = mfcc4(uav_raw, 1)\n",
    "print(mfcc_uav.shape, y_uav.shape)\n",
    "mfcc_none, y_none = mfcc4(none_raw, 0)\n",
    "print(mfcc_none.shape, y_none.shape)\n",
    "'''\n",
    "mfcc_uav = mfcc(uav_raw)\n",
    "mfcc_loaded = mfcc(loaded_raw)\n",
    "mfcc_none = mfcc(none_raw)\n",
    "print(len(mfcc_uav),len(mfcc_loaded),len(mfcc_none) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Features normalization with *mean* and *std*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stacking of a given number of frames to get temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71586,) 2\n",
      "(35159,) 1\n",
      "(168891,) 0\n",
      "(275636, 20) (275636,)\n"
     ]
    }
   ],
   "source": [
    "# or should we give one label to one chunk?\n",
    "y_uav = np.ones(mfcc_uav.shape[1], dtype=int)*2\n",
    "y_loaded = np.ones(mfcc_loaded.shape[1], dtype=int)\n",
    "y_none =np.zeros(mfcc_none.shape[1], dtype=int)\n",
    "\n",
    "print(y_uav.shape, y_uav[0])\n",
    "print(y_loaded.shape, y_loaded[0])\n",
    "print(y_none.shape, y_none[0])\n",
    "\n",
    "X = np.hstack((mfcc_uav, mfcc_loaded))\n",
    "X = np.hstack((X, mfcc_none)).T\n",
    "\n",
    "y = np.hstack((y_uav, y_loaded))\n",
    "y = np.hstack((y, y_none))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275636, 3)\n",
      "[0. 0. 1.] [0. 0. 1.] [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "n_labels = y.shape[0]\n",
    "n_unique_labels = 3\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "print(y_encoded.shape)\n",
    "print(y_encoded[0], y_encoded[40000],y_encoded[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmfcc_uav_list = mfcc_uav.tolist()\\nmfcc_uav_list = mfcc_uav_list\\nfig = plt.figure(figsize=(15,9))\\nax = fig.add_subplot(1,1,1)\\nax.plot(np.linspace(0,len(mfcc_uav_list), len(mfcc_uav_list)),mfcc_uav_list)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mfcc_uav_list = mfcc_uav.tolist()\n",
    "mfcc_uav_list = mfcc_uav_list\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.linspace(0,len(mfcc_uav_list), len(mfcc_uav_list)),mfcc_uav_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(275636, 20) (275636, 3)\n"
     ]
    }
   ],
   "source": [
    "dataX = X\n",
    "dataY = y_encoded\n",
    "print(y_encoded)\n",
    "print(dataX.shape, dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHot(dataX, dataY, seq_length):\n",
    "    X_hot_list= []\n",
    "    Y_hot_tmp = dataY[seq_length-1:]\n",
    "\n",
    "    for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "        _x = dataX[i:i + seq_length]\n",
    "        #if i<10:\n",
    "            #print(_x, \"->\", Y_hot_tmp[i])\n",
    "        X_hot_list.append(_x)\n",
    "\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    Y_hot= Y_hot_tmp.reshape((len(Y_hot_tmp),n_unique_labels))\n",
    "    return X_hot[:], Y_hot[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275621, 16, 20) (275621, 3)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 16 #layer\n",
    "X_hot, Y_hot = makeHot(dataX, dataY, seq_length)\n",
    "print(X_hot.shape, Y_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self,X,Y,BatchSize):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.len = len(Y)\n",
    "        self.bs = BatchSize\n",
    "        self.bs_i = 0\n",
    "    def getBatchData(self):\n",
    "        s = self.bs_i\n",
    "        e = self.bs_i + self.bs\n",
    "        if e> self.len:\n",
    "            e -= self.len\n",
    "            result =  np.vstack((self.X[s:],self.X[:e])), np.vstack((self.Y[s:],self.Y[:e]))\n",
    "        else:\n",
    "            result =  self.X[s:e], self.Y[s:e]\n",
    "            \n",
    "        self.bs_i = e\n",
    "        return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [11, 12, 13]\n",
      "[4, 5, 6] [14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "dataX = [1,2,3,4,5,6,7,8]\n",
    "dataY = [11,12,13,14,15,16,17,18]\n",
    "D = Data(dataX, dataY,3)\n",
    "x, y = D.getBatchData()\n",
    "print(x,y)\n",
    "x, y = D.getBatchData()\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_hot, Y_hot, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "traindata = Data(X_train,y_train,batch_size)\n",
    "testdata = Data(X_test,y_test,batch_size)\n",
    "valdata = Data(X_val,y_val,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176396, 16, 20) (55125, 16, 20) (44100, 16, 20)\n",
      "(176396, 3) (55125, 3) (44100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape,X_val.shape)\n",
    "print(y_train.shape, y_test.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnp.save('../data/Xy/X_train2', X_train)\\nnp.save('../data/Xy/X_test2', X_test)\\nnp.save('../data/Xy/y_train2', y_train)\\nnp.save('../data/Xy/y_test2', y_test)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "np.save('../data/Xy/X_train2', X_train)\n",
    "np.save('../data/Xy/X_test2', X_test)\n",
    "np.save('../data/Xy/y_train2', y_train)\n",
    "np.save('../data/Xy/y_test2', y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = np.load('../data/Xy/X_train2.npy')\\nX_test = np.load('../data/Xy/X_test2.npy')\\ny_train = np.load('../data/Xy/y_train2.npy')\\ny_test = np.load('../data/Xy/y_test2.npy')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = np.load('../data/Xy/X_train2.npy')\n",
    "X_test = np.load('../data/Xy/X_test2.npy')\n",
    "y_train = np.load('../data/Xy/y_train2.npy')\n",
    "y_test = np.load('../data/Xy/y_test2.npy')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size\n",
    "num_classes = N_MFCC            #분류할 사전의 크기 \n",
    "\n",
    "learning_rate = 0.01\n",
    "sequence_length = seq_length #9         \n",
    "\n",
    "output_dim = n_unique_labels\n",
    "layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, sequence_length,num_classes], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim], name=\"Y\")\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=num_classes, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell]*layers, state_is_tuple= True)\n",
    "\n",
    "BatchSize = tf.placeholder(tf.int32, [], name='BatchSize')\n",
    "initial_state = cell.zero_state(BatchSize, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X,initial_state=initial_state,dtype=tf.float32)\n",
    "\n",
    "dense1 = tf.contrib.layers.fully_connected(outputs[:,-1], output_dim, activation_fn=None)\n",
    "dense2 = tf.layers.dense(inputs=dense1, units=num_classes, activation=tf.nn.relu)\n",
    "\n",
    "Y_pred= tf.layers.dense(inputs=dense2, units=output_dim)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Y_pred, labels=Y))\n",
    "lr = tf.placeholder(tf.float32,shape=(), name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(lr).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.24285461e+02,  1.05689688e+02,  2.34859049e+01,\n",
       "         1.56318004e+01,  5.53109457e+00,  8.71770189e+00,\n",
       "         6.21920751e+00, -9.77620163e-01,  6.41941339e+00,\n",
       "         6.89265910e+00, -3.88062747e+00, -2.30095251e+00,\n",
       "         1.71102388e-01,  2.29457925e+00,  9.54123633e+00,\n",
       "         5.03520078e+00,  7.76846924e-01,  3.28094293e+00,\n",
       "         8.47739353e-01,  3.16145109e+00],\n",
       "       [-5.32972639e+02,  1.04444533e+02,  2.51869709e+01,\n",
       "         1.30460006e+01,  4.81677191e+00,  9.46346030e+00,\n",
       "         1.05919269e+01,  4.85616563e+00,  6.22374116e+00,\n",
       "         3.19416144e+00, -6.73717896e+00, -4.05999290e+00,\n",
       "         1.63683914e+00,  1.09187574e+00,  6.84105776e+00,\n",
       "         4.25543155e+00, -2.68917616e+00,  1.43046370e+00,\n",
       "        -2.27906680e+00,  4.28891601e+00],\n",
       "       [-5.26164647e+02,  1.09428217e+02,  2.24643161e+01,\n",
       "         1.20741965e+01,  2.50434022e-01,  8.15456427e+00,\n",
       "         9.48548403e+00,  2.20058872e+00,  4.22555358e+00,\n",
       "         4.21675033e+00, -5.35122344e+00, -1.86718186e+00,\n",
       "         1.51564316e+00,  9.42337593e-01,  7.94594513e+00,\n",
       "         3.09591809e-01, -2.01062394e+00,  6.71132600e+00,\n",
       "         2.99449342e+00,  6.34267300e+00],\n",
       "       [-5.24780971e+02,  1.09346775e+02,  2.73955409e+01,\n",
       "         1.52139292e+01,  1.95729627e+00,  7.48722109e+00,\n",
       "         9.25424405e+00, -1.11482911e+00,  3.30397172e+00,\n",
       "         1.66502250e+00, -4.51058803e+00,  2.90384435e+00,\n",
       "         3.88833542e+00,  5.40662907e+00,  1.17781740e+01,\n",
       "         3.65828719e-01, -8.49825125e-01,  6.26301789e+00,\n",
       "         4.21622622e-01,  3.91078397e+00],\n",
       "       [-5.22463485e+02,  1.11095263e+02,  2.99477621e+01,\n",
       "         1.28801541e+01,  4.14054459e-01,  7.59062212e+00,\n",
       "         8.17172926e+00,  9.44367210e-02,  6.45009502e+00,\n",
       "         3.22621373e+00, -5.53764219e+00,  1.20602488e+00,\n",
       "         5.38474985e-01,  5.16083310e+00,  9.89562218e+00,\n",
       "         2.44459244e+00, -2.29583138e+00,  4.74365216e+00,\n",
       "         4.63932335e+00,  7.85671391e+00],\n",
       "       [-5.22841111e+02,  1.14127817e+02,  3.00217148e+01,\n",
       "         1.23730635e+01,  1.79300510e+00,  7.36882448e+00,\n",
       "         1.06050525e+01,  5.13661639e+00,  7.28486508e+00,\n",
       "         4.89633984e+00, -6.00827326e+00,  5.95416494e+00,\n",
       "         3.24255747e+00,  2.66056800e+00,  1.01017467e+01,\n",
       "         7.21828794e+00,  1.93294281e+00,  1.97927434e+00,\n",
       "        -4.38621125e-01,  1.37239639e+00],\n",
       "       [-5.30148578e+02,  1.11471550e+02,  3.06429098e+01,\n",
       "         1.39443707e+01,  5.80387578e+00,  1.80101750e+00,\n",
       "         1.12513264e+01,  5.87467741e+00,  5.78412296e+00,\n",
       "         3.87220993e+00, -6.77896462e+00,  8.73828410e+00,\n",
       "         4.17059147e+00,  2.99437333e+00,  1.23994385e+01,\n",
       "         8.20245935e+00,  5.92279166e+00,  1.52256433e+00,\n",
       "         1.32475645e-01, -3.49606546e+00],\n",
       "       [-5.33533172e+02,  1.01215283e+02,  2.56211999e+01,\n",
       "         1.26515492e+01,  4.18293342e+00,  1.20920102e+01,\n",
       "         1.73803966e+01,  1.39426353e+01,  8.06785999e+00,\n",
       "         1.82537033e-01, -4.14719337e+00, -2.58082694e+00,\n",
       "         4.83618317e-01,  9.57124005e+00,  1.34182814e+01,\n",
       "         1.11977230e+01,  4.03131225e-01,  8.49435647e-01,\n",
       "        -5.79813435e+00,  4.19986296e+00],\n",
       "       [-5.23311141e+02,  1.07184145e+02,  2.64154328e+01,\n",
       "         1.14502910e+01,  3.18752009e+00,  8.94860444e+00,\n",
       "         1.02084464e+01,  6.10896961e+00,  9.60885122e+00,\n",
       "         4.37493019e+00, -3.45223941e+00, -8.47626550e-01,\n",
       "        -3.03824717e+00,  1.77953875e+00,  9.09068117e+00,\n",
       "         8.66608068e+00,  3.73226395e+00,  6.22884317e+00,\n",
       "        -1.54234024e+00,  6.19513925e+00],\n",
       "       [-5.21343752e+02,  1.08873409e+02,  2.27903068e+01,\n",
       "         9.63695106e+00,  3.80445930e+00,  1.24948685e+01,\n",
       "         1.14717141e+01,  6.73730971e+00,  1.01213538e+01,\n",
       "         7.73833165e+00,  8.92758029e-01,  3.55159718e+00,\n",
       "        -7.02210211e-01,  1.30840577e+00,  5.21327781e+00,\n",
       "         3.75792177e+00,  1.18221687e+00,  7.73093960e+00,\n",
       "         8.97563548e-01,  6.70101446e-01],\n",
       "       [-5.22447232e+02,  1.09337047e+02,  2.63046092e+01,\n",
       "         1.06842969e+01,  3.98603023e+00,  8.60328484e+00,\n",
       "         1.19104257e+01,  6.82376387e+00,  7.82534383e+00,\n",
       "         9.65794342e+00, -3.61158334e-01,  5.56412982e+00,\n",
       "         3.67226380e+00,  2.85879640e+00,  7.02080744e+00,\n",
       "         3.73945163e+00,  4.18034807e+00,  1.04680046e+01,\n",
       "         3.22985431e+00,  2.53153472e+00],\n",
       "       [-5.24333692e+02,  1.08437677e+02,  2.67913110e+01,\n",
       "         8.43588136e+00,  5.96248014e+00,  6.60030002e+00,\n",
       "         6.29074339e+00,  5.18486708e+00,  1.00521596e+01,\n",
       "         8.85919530e+00, -3.45830610e+00,  5.06100506e+00,\n",
       "         3.13426636e+00,  4.86581244e+00,  1.20818448e+01,\n",
       "         4.87769399e+00,  1.60431830e-01,  6.71944445e+00,\n",
       "         4.81743078e+00,  3.15057793e+00],\n",
       "       [-5.25320436e+02,  1.09830815e+02,  2.74081485e+01,\n",
       "         8.39179843e+00,  3.76118583e+00,  9.15936249e+00,\n",
       "         1.18393548e+01,  5.86322531e+00,  1.37822893e+01,\n",
       "         1.03492998e+01, -3.45144314e+00,  9.78402376e-01,\n",
       "         8.13200534e-01,  2.01339582e+00,  9.07010663e+00,\n",
       "         4.70474301e+00,  2.94361989e-02,  7.23437117e+00,\n",
       "         3.85706523e+00,  5.46338552e+00],\n",
       "       [-5.25968421e+02,  1.08421938e+02,  2.10463372e+01,\n",
       "         9.61344961e+00,  4.05557117e+00,  1.22721635e+01,\n",
       "         1.58595365e+01,  4.46826286e+00,  1.35541083e+01,\n",
       "         9.58389228e+00, -4.49858609e+00, -2.46346881e-01,\n",
       "         8.96562639e-01,  5.88469732e+00,  1.25284677e+01,\n",
       "         6.94709451e+00,  1.45917647e+00,  8.82152950e+00,\n",
       "         3.05504888e+00,  5.29749943e+00],\n",
       "       [-5.22138325e+02,  1.11306164e+02,  2.09658357e+01,\n",
       "         1.09515274e+01,  4.61060809e+00,  8.70555777e+00,\n",
       "         7.77620817e+00,  8.32606570e+00,  1.76091905e+01,\n",
       "         9.52288589e+00, -1.53317441e+00,  4.26308835e+00,\n",
       "         2.18978804e+00,  5.59248531e+00,  1.12791632e+01,\n",
       "         2.01035349e+00, -1.65971877e-01,  1.08373467e+01,\n",
       "         1.96886096e+00,  2.11335251e+00],\n",
       "       [-5.22557505e+02,  1.10442239e+02,  2.55430127e+01,\n",
       "         1.35975363e+01,  5.30960031e+00,  6.50105340e+00,\n",
       "         6.21651356e+00,  9.52931092e+00,  1.58219493e+01,\n",
       "         1.03309546e+01, -2.10262400e+00,  5.79222426e+00,\n",
       "         4.75864631e+00,  4.49002929e+00,  8.57403100e+00,\n",
       "         5.18003605e+00,  5.96609574e+00,  1.13990624e+01,\n",
       "         4.54088484e+00,  1.34916625e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(traindata.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x, y = traindata.getBatchData()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 0.6642764806747437 \tvalidation: 72.327%\n",
      "[step: 1] loss: 0.4816092848777771 \tvalidation: 78.460%\n",
      "[step: 2] loss: 0.387756884098053 \tvalidation: 82.819%\n",
      "[step: 3] loss: 0.3641592264175415 \tvalidation: 84.236%\n",
      "[step: 4] loss: 0.3416106104850769 \tvalidation: 85.018%\n",
      "[step: 5] loss: 0.3418843746185303 \tvalidation: 85.184%\n",
      "[step: 6] loss: 0.31423819065093994 \tvalidation: 86.011%\n",
      "[step: 7] loss: 0.30728307366371155 \tvalidation: 86.016%\n",
      "[step: 8] loss: 0.27657267451286316 \tvalidation: 86.739%\n",
      "[step: 9] loss: 0.2866363525390625 \tvalidation: 88.737%\n",
      "[step: 10] loss: 0.282417356967926 \tvalidation: 89.229%\n",
      "[step: 11] loss: 0.2790994346141815 \tvalidation: 89.853%\n",
      "[step: 12] loss: 0.2722412943840027 \tvalidation: 89.628%\n",
      "[step: 13] loss: 0.27140945196151733 \tvalidation: 89.608%\n",
      "[step: 14] loss: 0.2405080795288086 \tvalidation: 90.066%\n",
      "[step: 15] loss: 0.26035743951797485 \tvalidation: 89.927%\n",
      "[step: 16] loss: 0.2578655481338501 \tvalidation: 90.043%\n",
      "[step: 17] loss: 0.2742122411727905 \tvalidation: 90.726%\n",
      "[step: 18] loss: 0.23724672198295593 \tvalidation: 90.193%\n",
      "[step: 19] loss: 0.24043285846710205 \tvalidation: 91.129%\n",
      "[step: 20] loss: 0.21235927939414978 \tvalidation: 91.220%\n",
      "[step: 21] loss: 0.19982625544071198 \tvalidation: 91.440%\n",
      "[step: 22] loss: 0.2271943986415863 \tvalidation: 91.755%\n",
      "[step: 23] loss: 0.20901882648468018 \tvalidation: 90.757%\n",
      "[step: 24] loss: 0.21986818313598633 \tvalidation: 91.687%\n",
      "[step: 25] loss: 0.24099035561084747 \tvalidation: 91.816%\n",
      "[step: 26] loss: 0.2048410177230835 \tvalidation: 91.864%\n",
      "[step: 27] loss: 0.21302878856658936 \tvalidation: 91.404%\n",
      "[step: 28] loss: 0.21344608068466187 \tvalidation: 91.773%\n",
      "[step: 29] loss: 0.21434050798416138 \tvalidation: 91.866%\n",
      "[step: 30] loss: 0.1919425129890442 \tvalidation: 91.347%\n",
      "[step: 31] loss: 0.23033413290977478 \tvalidation: 92.168%\n",
      "[step: 32] loss: 0.20169192552566528 \tvalidation: 91.982%\n",
      "[step: 33] loss: 0.1968388557434082 \tvalidation: 92.259%\n",
      "[step: 34] loss: 0.20611709356307983 \tvalidation: 92.283%\n",
      "[step: 35] loss: 0.2001844048500061 \tvalidation: 91.952%\n",
      "[step: 36] loss: 0.20668312907218933 \tvalidation: 92.363%\n",
      "[step: 37] loss: 0.2046719491481781 \tvalidation: 92.215%\n",
      "[step: 38] loss: 0.18841420114040375 \tvalidation: 92.088%\n",
      "[step: 39] loss: 0.20749531686306 \tvalidation: 92.256%\n",
      "[step: 40] loss: 0.19586730003356934 \tvalidation: 92.696%\n",
      "[step: 41] loss: 0.18506988883018494 \tvalidation: 92.506%\n",
      "[step: 42] loss: 0.19397445023059845 \tvalidation: 92.497%\n",
      "[step: 43] loss: 0.17480087280273438 \tvalidation: 92.331%\n",
      "[step: 44] loss: 0.19688448309898376 \tvalidation: 92.556%\n",
      "[step: 45] loss: 0.16453970968723297 \tvalidation: 92.828%\n",
      "[step: 46] loss: 0.17892765998840332 \tvalidation: 92.016%\n",
      "[step: 47] loss: 0.1890714466571808 \tvalidation: 93.109%\n",
      "[step: 48] loss: 0.19604849815368652 \tvalidation: 92.902%\n",
      "[step: 49] loss: 0.19417095184326172 \tvalidation: 93.011%\n",
      "[step: 50] loss: 0.1752735674381256 \tvalidation: 93.045%\n",
      "[step: 51] loss: 0.19708004593849182 \tvalidation: 93.000%\n",
      "[step: 52] loss: 0.17466670274734497 \tvalidation: 93.020%\n",
      "[step: 53] loss: 0.18840615451335907 \tvalidation: 93.014%\n",
      "[step: 54] loss: 0.15541145205497742 \tvalidation: 92.379%\n",
      "[step: 55] loss: 0.16581475734710693 \tvalidation: 93.138%\n",
      "[step: 56] loss: 0.17563793063163757 \tvalidation: 93.270%\n",
      "[step: 57] loss: 0.18299540877342224 \tvalidation: 93.238%\n",
      "[step: 58] loss: 0.18040211498737335 \tvalidation: 93.009%\n",
      "[step: 59] loss: 0.18214742839336395 \tvalidation: 92.937%\n",
      "[step: 60] loss: 0.17517316341400146 \tvalidation: 93.020%\n",
      "[step: 61] loss: 0.17047293484210968 \tvalidation: 93.290%\n",
      "[step: 62] loss: 0.17409338057041168 \tvalidation: 93.082%\n",
      "[step: 63] loss: 0.16965755820274353 \tvalidation: 93.354%\n",
      "[step: 64] loss: 0.17360498011112213 \tvalidation: 93.297%\n",
      "[step: 65] loss: 0.18161766231060028 \tvalidation: 92.950%\n",
      "[step: 66] loss: 0.1850506067276001 \tvalidation: 92.932%\n",
      "[step: 67] loss: 0.1707211434841156 \tvalidation: 93.449%\n",
      "[step: 68] loss: 0.154646635055542 \tvalidation: 93.304%\n",
      "[step: 69] loss: 0.1707039624452591 \tvalidation: 93.488%\n",
      "[step: 70] loss: 0.17137515544891357 \tvalidation: 93.014%\n",
      "[step: 71] loss: 0.17008762061595917 \tvalidation: 93.365%\n",
      "[step: 72] loss: 0.16372814774513245 \tvalidation: 93.404%\n",
      "[step: 73] loss: 0.1475844830274582 \tvalidation: 93.145%\n",
      "[step: 74] loss: 0.14954760670661926 \tvalidation: 93.091%\n",
      "[step: 75] loss: 0.16359148919582367 \tvalidation: 93.478%\n",
      "[step: 76] loss: 0.17305096983909607 \tvalidation: 93.218%\n",
      "[step: 77] loss: 0.15758875012397766 \tvalidation: 93.626%\n",
      "[step: 78] loss: 0.17325359582901 \tvalidation: 93.372%\n",
      "[step: 79] loss: 0.16918066143989563 \tvalidation: 93.649%\n",
      "[step: 80] loss: 0.1670680046081543 \tvalidation: 93.603%\n",
      "[step: 81] loss: 0.17162206768989563 \tvalidation: 93.512%\n",
      "[step: 82] loss: 0.1428455263376236 \tvalidation: 93.567%\n",
      "[step: 83] loss: 0.15676751732826233 \tvalidation: 93.488%\n",
      "[step: 84] loss: 0.170511394739151 \tvalidation: 93.247%\n",
      "[step: 85] loss: 0.1473255157470703 \tvalidation: 93.544%\n",
      "[step: 86] loss: 0.15865033864974976 \tvalidation: 92.875%\n",
      "[step: 87] loss: 0.18216611444950104 \tvalidation: 93.830%\n",
      "[step: 88] loss: 0.15889939665794373 \tvalidation: 93.819%\n",
      "[step: 89] loss: 0.14878889918327332 \tvalidation: 93.966%\n",
      "[step: 90] loss: 0.14174199104309082 \tvalidation: 93.580%\n",
      "[step: 91] loss: 0.15645958483219147 \tvalidation: 93.533%\n",
      "[step: 92] loss: 0.1426316797733307 \tvalidation: 93.707%\n",
      "[step: 93] loss: 0.14933985471725464 \tvalidation: 93.880%\n",
      "[step: 94] loss: 0.15508171916007996 \tvalidation: 93.435%\n",
      "[step: 95] loss: 0.1501477062702179 \tvalidation: 93.782%\n",
      "[step: 96] loss: 0.1533161997795105 \tvalidation: 93.522%\n",
      "[step: 97] loss: 0.15344871580600739 \tvalidation: 93.576%\n",
      "[step: 98] loss: 0.18059475719928741 \tvalidation: 93.587%\n",
      "[step: 99] loss: 0.16317012906074524 \tvalidation: 93.780%\n",
      "[step: 100] loss: 0.16602090001106262 \tvalidation: 93.247%\n",
      "[step: 101] loss: 0.13767129182815552 \tvalidation: 93.497%\n",
      "[step: 102] loss: 0.15699025988578796 \tvalidation: 93.744%\n",
      "[step: 103] loss: 0.15872550010681152 \tvalidation: 93.812%\n",
      "[step: 104] loss: 0.17416910827159882 \tvalidation: 93.066%\n",
      "[step: 105] loss: 0.17186816036701202 \tvalidation: 93.422%\n",
      "[step: 106] loss: 0.16769549250602722 \tvalidation: 93.766%\n",
      "[step: 107] loss: 0.14822903275489807 \tvalidation: 93.837%\n",
      "[step: 108] loss: 0.17158818244934082 \tvalidation: 93.853%\n",
      "[step: 109] loss: 0.15254348516464233 \tvalidation: 93.805%\n",
      "[step: 110] loss: 0.13898570835590363 \tvalidation: 93.952%\n",
      "[step: 111] loss: 0.13623468577861786 \tvalidation: 94.059%\n",
      "[step: 112] loss: 0.16596224904060364 \tvalidation: 93.771%\n",
      "[step: 113] loss: 0.1680009514093399 \tvalidation: 93.036%\n",
      "[step: 114] loss: 0.1412210911512375 \tvalidation: 94.061%\n",
      "[step: 115] loss: 0.14063221216201782 \tvalidation: 93.880%\n",
      "[step: 116] loss: 0.15472422540187836 \tvalidation: 93.950%\n",
      "[step: 117] loss: 0.16258981823921204 \tvalidation: 94.036%\n",
      "[step: 118] loss: 0.13532817363739014 \tvalidation: 94.029%\n",
      "[step: 119] loss: 0.14889122545719147 \tvalidation: 93.732%\n",
      "[step: 120] loss: 0.1401120275259018 \tvalidation: 93.821%\n",
      "[step: 121] loss: 0.14191380143165588 \tvalidation: 93.333%\n",
      "[step: 122] loss: 0.17191573977470398 \tvalidation: 94.277%\n",
      "[step: 123] loss: 0.15832969546318054 \tvalidation: 94.020%\n",
      "[step: 124] loss: 0.15574601292610168 \tvalidation: 94.188%\n",
      "[step: 125] loss: 0.14791664481163025 \tvalidation: 94.009%\n",
      "[step: 126] loss: 0.1558503955602646 \tvalidation: 94.254%\n",
      "[step: 127] loss: 0.16112518310546875 \tvalidation: 93.744%\n",
      "[step: 128] loss: 0.14876143634319305 \tvalidation: 93.694%\n",
      "[step: 129] loss: 0.14179031550884247 \tvalidation: 93.710%\n",
      "[step: 130] loss: 0.14073410630226135 \tvalidation: 94.098%\n",
      "[step: 131] loss: 0.14940303564071655 \tvalidation: 93.837%\n",
      "[step: 132] loss: 0.12995748221874237 \tvalidation: 93.571%\n",
      "[step: 133] loss: 0.14416161179542542 \tvalidation: 93.551%\n",
      "[step: 134] loss: 0.17649737000465393 \tvalidation: 94.032%\n",
      "[step: 135] loss: 0.15406790375709534 \tvalidation: 93.367%\n",
      "[step: 136] loss: 0.13452661037445068 \tvalidation: 94.190%\n",
      "[step: 137] loss: 0.16575424373149872 \tvalidation: 94.082%\n",
      "[step: 138] loss: 0.14919671416282654 \tvalidation: 93.596%\n",
      "[step: 139] loss: 0.1440407931804657 \tvalidation: 93.710%\n",
      "[step: 140] loss: 0.14179211854934692 \tvalidation: 94.138%\n",
      "[step: 141] loss: 0.16023126244544983 \tvalidation: 93.712%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 142] loss: 0.16030333936214447 \tvalidation: 93.948%\n",
      "[step: 143] loss: 0.13213954865932465 \tvalidation: 94.088%\n",
      "[step: 144] loss: 0.14252784848213196 \tvalidation: 93.905%\n",
      "[step: 145] loss: 0.16209042072296143 \tvalidation: 93.773%\n",
      "[step: 146] loss: 0.1557134985923767 \tvalidation: 94.111%\n",
      "[step: 147] loss: 0.14099454879760742 \tvalidation: 94.263%\n",
      "[step: 148] loss: 0.12422593683004379 \tvalidation: 94.061%\n",
      "[step: 149] loss: 0.16248267889022827 \tvalidation: 93.925%\n",
      "[step: 150] loss: 0.14798504114151 \tvalidation: 94.236%\n",
      "[step: 151] loss: 0.1216229498386383 \tvalidation: 93.980%\n",
      "[step: 152] loss: 0.15735793113708496 \tvalidation: 94.077%\n",
      "[step: 153] loss: 0.15195557475090027 \tvalidation: 94.204%\n",
      "[step: 154] loss: 0.15862473845481873 \tvalidation: 93.952%\n",
      "[step: 155] loss: 0.13840103149414062 \tvalidation: 94.002%\n",
      "[step: 156] loss: 0.17088769376277924 \tvalidation: 93.859%\n",
      "[step: 157] loss: 0.13311801850795746 \tvalidation: 93.998%\n",
      "[step: 158] loss: 0.13870546221733093 \tvalidation: 94.243%\n",
      "[step: 159] loss: 0.14693583548069 \tvalidation: 94.340%\n",
      "[step: 160] loss: 0.15082119405269623 \tvalidation: 93.406%\n",
      "[step: 161] loss: 0.14655077457427979 \tvalidation: 94.025%\n",
      "[step: 162] loss: 0.15036383271217346 \tvalidation: 94.426%\n",
      "[step: 163] loss: 0.1322944611310959 \tvalidation: 94.075%\n",
      "[step: 164] loss: 0.16524598002433777 \tvalidation: 94.236%\n",
      "[step: 165] loss: 0.12072011828422546 \tvalidation: 94.531%\n",
      "[step: 166] loss: 0.1332535445690155 \tvalidation: 94.537%\n",
      "[step: 167] loss: 0.13595838844776154 \tvalidation: 93.610%\n",
      "[step: 168] loss: 0.13215871155261993 \tvalidation: 94.000%\n",
      "[step: 169] loss: 0.13449320197105408 \tvalidation: 94.295%\n",
      "[step: 170] loss: 0.1359836310148239 \tvalidation: 94.295%\n",
      "[step: 171] loss: 0.16197358071804047 \tvalidation: 93.862%\n",
      "[step: 172] loss: 0.12208660691976547 \tvalidation: 94.299%\n",
      "[step: 173] loss: 0.14445078372955322 \tvalidation: 94.299%\n",
      "[step: 174] loss: 0.13934792578220367 \tvalidation: 94.317%\n",
      "[step: 175] loss: 0.1379852294921875 \tvalidation: 94.249%\n",
      "[step: 176] loss: 0.147475004196167 \tvalidation: 94.247%\n",
      "[step: 177] loss: 0.12316443026065826 \tvalidation: 93.671%\n",
      "[step: 178] loss: 0.12116129696369171 \tvalidation: 94.431%\n",
      "[step: 179] loss: 0.13264819979667664 \tvalidation: 93.844%\n",
      "[step: 180] loss: 0.15872511267662048 \tvalidation: 92.941%\n",
      "[step: 181] loss: 0.16406777501106262 \tvalidation: 94.417%\n",
      "[step: 182] loss: 0.13513199985027313 \tvalidation: 94.104%\n",
      "[step: 183] loss: 0.12037932872772217 \tvalidation: 94.204%\n",
      "[step: 184] loss: 0.12871046364307404 \tvalidation: 94.488%\n",
      "[step: 185] loss: 0.15194302797317505 \tvalidation: 94.308%\n",
      "[step: 186] loss: 0.15820816159248352 \tvalidation: 94.218%\n",
      "[step: 187] loss: 0.1291731894016266 \tvalidation: 94.739%\n",
      "[step: 188] loss: 0.15094047784805298 \tvalidation: 94.236%\n",
      "[step: 189] loss: 0.1273452490568161 \tvalidation: 94.510%\n",
      "[step: 190] loss: 0.12354093790054321 \tvalidation: 94.385%\n",
      "[step: 191] loss: 0.12850254774093628 \tvalidation: 94.236%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "init = tf.global_variables_initializer()\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "step_loss = 999999.0\n",
    "model_path = '../models/RNN/my_RNN_model'\n",
    "saver = tf.train.Saver()\n",
    "training_epochs = 200\n",
    "# Training step\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "#learning_rate_ = [i*0.001 for i in range(20,10,-1)]\n",
    "#for learning_rate in [0.02, 0.01]:\n",
    "#    feed = {lr:learning_rate, BatchSize: batch_size}\n",
    "N = int(len(valdata.Y) / batch_size) + 1\n",
    "for i in range(training_epochs):\n",
    "    feed = {lr:learning_rate, BatchSize: batch_size}\n",
    "    \n",
    "    for n in range(N):\n",
    "        x,y = traindata.getBatchData()\n",
    "        feed[X], feed[Y] = x, y\n",
    "        step_loss_prev = step_loss\n",
    "        _, step_loss = sess.run([train, cost], feed_dict=feed)\n",
    "        cost_history = np.append(cost_history,step_loss)\n",
    "        \n",
    "    y_pred = sess.run(tf.argmax(Y_pred,1),feed_dict={X: valdata.X, BatchSize: len(valdata.Y)})\n",
    "    y_true = sess.run(tf.argmax(valdata.Y,1))\n",
    "    accuracy_val = accuracy_score(y_pred, y_true)\n",
    "    \n",
    "    print(\"[step: {}] loss: {}\".format(i, step_loss), \"\\tvalidation: {:.3f}%\".format(accuracy_val * 100))    \n",
    "    \n",
    "print('')\n",
    "saver.save(sess, model_path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver.restore(sess, model_path)\n",
    "y_pred = sess.run(tf.argmax(Y_pred,1),feed_dict={X: testdata.X, BatchSize: len(testdata.Y)})\n",
    "y_true = sess.run(tf.argmax(testdata.Y,1))\n",
    "print(y_pred.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\") \n",
    "plt.axis([0,len(cost_history),0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_path_f = '../models/RNN/'\n",
    "filename = 'my_RNN_model_S9_40.meta'\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loader = tf.train.import_meta_graph(model_path_f+filename)\n",
    "loader.restore(sess, tf.train.latest_checkpoint(model_path_f))\n",
    "\n",
    "SR = 22050\n",
    "####\n",
    "justone = True\n",
    "\n",
    "while(justone):\n",
    "    justone = False\n",
    "    #print(\"start to record the audio.\")\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    #print(\"Recording finished.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    ####\n",
    "    filename1 = '../data/phantom/JUNE_01_PHANTOMS/wavs/22050/WSU_P2_LOADED_BACK_AND_FORTH.wav'\n",
    "    filename2 = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/canopy_heavy_wind.wav'\n",
    "    \n",
    "    sample, sample_rate = librosa.load(filename1,SR)\n",
    "    print(sample.shape)\n",
    "    \n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(sample, sample_rate)    \n",
    "    #showFreqTime([[sample, filename1, SR]])  \n",
    "\n",
    "    spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    dataX = spectrogram\n",
    "    #print(dataX.shape)\n",
    "    #print('delta shape:',dataX.shape)\n",
    "\n",
    "    X_hot_list= []\n",
    "    #print(dataX.shape[0] - seq_length+1)\n",
    "    for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "        _x = dataX[i:i + seq_length]\n",
    "        X_hot_list.append(_x)\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    #print(X_hot[0])\n",
    "    #print('\\n\\n\\n')\n",
    "    y_pred = sess.run(Y_pred,feed_dict={X: X_hot})\n",
    "    #y_pred[y_pred<0.5] = 0\n",
    "    #y_pred[y_pred>=0.5] = 1\n",
    "    print(y_pred[20:30] )\n",
    "    y_true = np.ones(shape=[y_pred.shape[0]])\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    \n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print(\"F-Score:\", round(f,3))\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    \n",
    "    if y_pred[0] == 1:\n",
    "        print('The sound is Drone')\n",
    "    else :\n",
    "        print('THe sound isn\\'t Drone')\n",
    "    \n",
    "\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
