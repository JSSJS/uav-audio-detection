{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "uav_path = './Record/unload/*.wav'\n",
    "loaded_path = './Record/load/*.wav'\n",
    "none_path = './Record/background/*.wav'\n",
    "\n",
    "uav_files = glob.glob(uav_path)\n",
    "loaded_files = glob.glob(loaded_path)\n",
    "none_files = glob.glob(none_path)\n",
    "\n",
    "SR = 44100\n",
    "sample_rate = SR\n",
    "\n",
    "n_mels = 40\n",
    "n_frame = 500\n",
    "window_size=1024\n",
    "hop_size=512\n",
    "\n",
    "sequence_length = 50 #layer\n",
    "n_unique_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "def load(files, sr=SR):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49786215,)\n",
      "(45730224,)\n",
      "(48921530,)\n"
     ]
    }
   ],
   "source": [
    "# initial\n",
    "none_raw = load(none_files)\n",
    "uav_raw = load(uav_files)\n",
    "loaded_raw = load(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Variables\n",
    "n_mfcc = 16\n",
    "n_frame = 16\n",
    "n_classes = 3\n",
    "n_channels = 1\n",
    "learning_rate = 0.0002  # 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(session, train_x, train_y):\n",
    "    print (\"\\nStart training\")\n",
    "    session.run(init)\n",
    "    for epoch in range(10):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = train_y[i*batch_size:(i+1)*batch_size]\n",
    "            _, c = session.run([optimizer, cost], feed_dict={X: batch_x, Y: batch_y})\n",
    "            if i % 100 == 0:\n",
    "                print (\"Epoch #%d step=%d cost=%f\" % (epoch, i, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(session, split_size=5):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    for train_idx, val_idx in kf.split(X_train2, y_train):\n",
    "        train_x = X_train2[train_idx]\n",
    "        train_y = y_train[train_idx]\n",
    "        val_x = X_train2[val_idx]\n",
    "        val_y = y_train[val_idx]\n",
    "        run_train(session, train_x, train_y)\n",
    "        y_true = session.run(tf.argmax(val_y,1))\n",
    "        y_pred = session.run(tf.argmax(logits,1),feed_dict={X: val_x})\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        results.append(accuracy_score(y_true, y_pred))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.02222408e+02 2.24740576e+02 1.35802361e+02 ... 2.96847090e-02\n",
      "  2.52862511e-03 2.12844749e-02]\n",
      " [2.96940132e-02 1.59778620e-02 6.54773627e-03 ... 5.11122128e-04\n",
      "  3.21802178e-04 3.77853838e-04]\n",
      " [2.23049691e-03 3.03739502e-04 3.05152668e-04 ... 1.12306643e-04\n",
      "  9.22759706e-05 4.38188929e-05]\n",
      " ...\n",
      " [1.33908831e-09 8.43796267e-09 8.57859966e-09 ... 5.82998506e-07\n",
      "  5.18313135e-07 5.19150173e-07]\n",
      " [1.15008615e-09 5.67973156e-09 6.33179071e-09 ... 5.03313496e-07\n",
      "  5.04695835e-07 3.76998037e-07]\n",
      " [1.01010746e-09 6.24981609e-09 4.83135602e-09 ... 4.57500739e-07\n",
      "  3.64037747e-07 4.76369383e-07]] 7.873009525194064e-10 401.7224888014053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 95550)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial\n",
    "none_spec = librosa.feature.melspectrogram(y=none_raw, sr=SR,n_fft=window_size, hop_length=hop_size, power=2.0, n_mels=40)\n",
    "\n",
    "uav_spec = librosa.feature.melspectrogram(y=uav_raw, sr=SR,n_fft=window_size, hop_length=hop_size, power=2.0, n_mels=40)\n",
    "\n",
    "load_spec = librosa.feature.melspectrogram(y=loaded_raw, sr=SR,n_fft=window_size, hop_length=hop_size, power=2.0, n_mels=40)\n",
    "\n",
    "print( load_spec, load_spec.min(), load_spec.max())\n",
    "load_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n",
      "(97239,) 0\n",
      "(89317,) 1\n",
      "(95550,) 2\n"
     ]
    }
   ],
   "source": [
    "#initail\n",
    "y_none =np.zeros(none_spec.shape[1], dtype=int)\n",
    "y_uav = np.ones(uav_spec.shape[1], dtype=int)\n",
    "y_loaded = np.ones(load_spec.shape[1], dtype=int)*2\n",
    "\n",
    "print(len(none_spec),len(uav_spec),len(load_spec))\n",
    "print(y_none.shape, y_none[0])\n",
    "print(y_uav.shape, y_uav[0])\n",
    "print(y_loaded.shape, y_loaded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial\n",
    "X_mfcc = np.hstack((none_spec, uav_spec))\n",
    "X_mfcc = np.hstack((X_mfcc, load_spec))\n",
    "X_mfcc = X_mfcc.T\n",
    "\n",
    "y = np.hstack((y_none, y_uav))\n",
    "y = np.hstack((y, y_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "n_labels = y.shape[0]\n",
    "y_encoded = np.zeros((n_labels, n_unique_labels))\n",
    "y_encoded[np.arange(n_labels), y] = 1\n",
    "\n",
    "dataX = X_mfcc\n",
    "dataY = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHot(dataX, dataY, sequence_length):\n",
    "    X_hot_list= []\n",
    "    Y_hot_tmp = dataY[sequence_length-1:]\n",
    "\n",
    "    for i in range(0, dataX.shape[0] - sequence_length+1):\n",
    "        _x = dataX[i:i + sequence_length]\n",
    "        X_hot_list.append(_x)\n",
    "\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    Y_hot= Y_hot_tmp.reshape((len(Y_hot_tmp),n_unique_labels))\n",
    "    return X_hot[:], Y_hot[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hot, Y_hot = makeHot( dataX, dataY, sequence_length)\n",
    "#X_hot, Y_hot = dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_hot, Y_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "np.save('./X_train2', X_train)\n",
    "np.save('./X_test2', X_test)\n",
    "np.save('./y_train2', y_train)\n",
    "np.save('./y_test2', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loading ###\n",
    "X_train = np.load('./X_train2.npy')\n",
    "X_test = np.load('./X_test2.npy')\n",
    "y_train = np.load('./y_train2.npy')\n",
    "y_test = np.load('./y_test2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,sequence_length*n_mels*n_channels])\n",
    "X = tf.reshape(X, [-1, sequence_length, n_mels, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,n_classes])\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=1, kernel_size=[3, 3],\n",
    "                         padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                padding=\"SAME\", strides=1)\n",
    "\n",
    "flat = tf.reshape(pool2, [-1, sequence_length*n_mels*1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=dense2, units=3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "Y_pred = tf.contrib.layers.fully_connected(logits,n_classes,activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model ###\n",
    "model_path = './spec'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "batch_size = 64\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = cross_validate(session)\n",
    "    print (\"Cross-validation result: %s\" % result)\n",
    "    y_true = session.run(tf.argmax(y_train,1))\n",
    "    y_pred = session.run(tf.argmax(logits,1),feed_dict={X: X_train2})\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print (\"Test accuracy: %f\" % accuracy_score(y_true, y_pred))\n",
    "    saver.save(session, model_path)\n",
    "    y_pred = session.run(tf.argmax(logits,1),feed_dict={X: X_test2})\n",
    "    y_true = session.run(tf.argmax(y_test,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show  pred result of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "### print true graph###\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.linspace(0,len(y_pred), len(y_pred)),y_true)\n",
    "\n",
    "### print pred graph###\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.linspace(0,len(y_pred), len(y_pred)),y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
